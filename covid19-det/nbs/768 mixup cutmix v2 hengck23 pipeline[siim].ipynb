{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"768 mixup cutmix v2 hengck23 pipeline[siim].ipynb","provenance":[{"file_id":"1r6fwPZUfesKm9odwVnB-UyIwzsa0KID6","timestamp":1623701113374},{"file_id":"11i35Q75Lrc9PnrlpHi5mI0aAPI7WAnKw","timestamp":1622307815280}],"collapsed_sections":[],"authorship_tag":"ABX9TyNreXKlFEO6P41jypdQ9G6F"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"2XQH3OaLq1-_"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMIRX_fD79N8","executionInfo":{"status":"ok","timestamp":1629046182991,"user_tz":-180,"elapsed":3,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#config consts\n","DATASET =     {'train':'train.tar.gz',\n","               'test':'test.tar.gz',\n","               'train_mask':'train_mask.tar.gz'}\n","\n","METADATA=     {'image_level':'train_image_level.csv',\n","               'study_level':'train_study_level.csv',\n","               'df_meta':'df_meta.csv',\n","               'df_fold_rand830':'df_fold_rand830.csv',\n","               'train_dup':'duplicate.txt',\n","               'sample_sub':'sample_submission.csv'}\n","\n","CFGMODEL_DIR_DICT = {'B3_512':'effb3-full-512-mask-v8/',\n","                     'B3_512_PNG': 'effb3-512-png-mask/',\n","                     'B4_512':'effb4-full-512-mask/',\n","                     'B5_600':'effb5-600-mask/',\n","                     'B5_640':'effb5-640-mask/',\n","                     'B5_640_M2': 'effb5-640-mask/',\n","                     'D121_640':'d121-640-mask/',\n","                     'D201_640':'d201-640-mask/',\n","                     'B7_768':'effb7-768-mask/',\n","                     'MLP_640':'mlp-640/',}\n","\n","INPUT_DIR ='/content/drive/My\\ Drive/kaggle/covid19-det/input/'\n","\n","OUTPUT_DIR = {'BSL':'/content/drive/My\\ Drive/kaggle/covid19-det/output/',\n","              'NORM':'/content/drive/My Drive/kaggle/covid19-det/output/'}\n","\n","IMPORT_DIR = '/content/drive/My Drive/kaggle/covid19-det/nbs/py/'\n","\n","HENGCK_IM_DIR=IMPORT_DIR+'hengck_code/dummy_01q/'\n","\n","WORK_DIR='/content/'\n","\n","DATASET_DIR_DICT = {'256': INPUT_DIR+'256_jpg/',\n","                    '512': INPUT_DIR+'512_jpg/',\n","                    '512_PNG': INPUT_DIR+'512_png/',\n","                    '600': INPUT_DIR+'600_jpg/',\n","                    '640': INPUT_DIR+'640_jpg/',\n","                    '640_M2':INPUT_DIR+'640_jpg_m2/',\n","                    '768':INPUT_DIR+'768_jpg/'}\n","\n","EXPERIMENT='SZ768_B7_NEWTEST'\n","EXPERIMENT_DIR = OUTPUT_DIR['BSL'] + EXPERIMENT+'/'\n","CFGMODEL_DIR = CFGMODEL_DIR_DICT['B7_768']\n","MASK_SIZE=(48,48)\n","L1_FACTOR=4\n","LR_FACTOR=0.1\n","MAX_LR_PLATEAU=20\n","PROBS=[0.2,0.2] #mixup, cutmix \n","DATASET_DIR = DATASET_DIR_DICT['768']\n","METADATA_DIR = INPUT_DIR+'metadata/'\n","FOLDS_SET=[0]\n","INITIAL_CHECKPOINTS=[None,None,None,None,None]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgTs_sntmBhY","executionInfo":{"status":"ok","timestamp":1628429781153,"user_tz":-180,"elapsed":21545,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"e32ae73c-cf0f-428e-dff4-e9eb49fafbac"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTWvq4iJPT07","executionInfo":{"status":"ok","timestamp":1628429932634,"user_tz":-180,"elapsed":22049,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"a07fe26d-6e09-4abf-ca16-0f9fa43bf2fc"},"source":["!pip install pydicom\n","!pip install madgrad\n","!pip install timm\n","\n","import sys\n","sys.path.append(HENGCK_IM_DIR)\n","sys.path.append(HENGCK_IM_DIR+CFGMODEL_DIR)\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","from common import *\n","\n","from siim import *\n","\n","# from lib.net.lookahead import *\n","# from lib.net.radam import *\n","from madgrad import MADGRAD\n","\n","from model import *\n","from dataset import *\n","\n","\n","def copy_dataset(ds_dict, ds_dir, work_dir):\n","  for record in ds_dict:\n","    print('copy', ds_dir+ds_dict[record], ' to', work_dir)\n","    !cp {ds_dir+ds_dict[record]} {work_dir}\n","    print('mkdir',work_dir+record)\n","    !mkdir {work_dir+record}\n","    print ('tar -xzf',work_dir+ds_dict[record],'-C',work_dir+record)\n","    !tar -xzf  {work_dir+ds_dict[record]} -C {work_dir+record}\n","    print ('rm ',work_dir+ds_dict[record])\n","    !rm {work_dir+ds_dict[record]}\n","def copy_metadata(md_dict,md_dir,work_dir):\n","  for record in md_dict:\n","    print('copy ', md_dir+md_dict[record],' to ',work_dir)\n","    !cp {md_dir+md_dict[record]} {work_dir}\n","copy_dataset(DATASET,DATASET_DIR, WORK_DIR)\n","copy_metadata(METADATA,METADATA_DIR,WORK_DIR)\n","!ls /content/\n","!mkdir {EXPERIMENT_DIR}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pydicom in /usr/local/lib/python3.7/dist-packages (2.2.0)\n","Requirement already satisfied: madgrad in /usr/local/lib/python3.7/dist-packages (1.1)\n","Collecting timm\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Installing collected packages: timm\n","Successfully installed timm-0.4.12\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/768_jpg/train.tar.gz  to /content/\n","mkdir /content/train\n","tar -xzf /content/train.tar.gz -C /content/train\n","rm  /content/train.tar.gz\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/768_jpg/test.tar.gz  to /content/\n","mkdir /content/test\n","tar -xzf /content/test.tar.gz -C /content/test\n","rm  /content/test.tar.gz\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/768_jpg/train_mask.tar.gz  to /content/\n","mkdir /content/train_mask\n","tar -xzf /content/train_mask.tar.gz -C /content/train_mask\n","rm  /content/train_mask.tar.gz\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/train_image_level.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/train_study_level.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_meta.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_fold_rand830.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/duplicate.txt  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/sample_submission.csv  to  /content/\n","df_fold_rand830.csv  sample_data\t    train_image_level.csv\n","df_meta.csv\t     sample_submission.csv  train_mask\n","drive\t\t     test\t\t    train_study_level.csv\n","duplicate.txt\t     train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qzt-bjlYQoZJ"},"source":["#----------------\n","import torch.cuda.amp as amp\n","\n","class AmpNet(Net):\n","    @torch.cuda.amp.autocast()\n","    def forward(self,*args):\n","        return super(AmpNet, self).forward(*args)\n","\n","is_mixed_precision = True  #True #False\n","#run_check_net()\n","\n","def rand_bboxes(size, gamma):\n","    W = size[0]\n","    H = size[1]\n","    GS = gamma.shape[0]\n","    cut_rat = np.sqrt(1. - gamma)\n","    cut_w = np.int_(W * cut_rat)\n","    cut_h = np.int_(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W,size=GS)\n","    cy = np.random.randint(H,size=GS)\n","\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n"," \n","    return bbx1, bby1, bbx2, bby2\n","\n","def do_mixup(batch1,batch2,alpha=0.4):\n","  bs = len(batch1['index'])\n","  gamma = np.random.beta(alpha, alpha, bs)\n","  gamma = torch.FloatTensor(np.max(np.stack((gamma,1-gamma)),axis=0))\n","  gamma_4 = gamma[:,None,None,None].cuda()\n","  gamma_2 = gamma[:,None].cuda()\n","\n","  mix_image = gamma_4*batch1['image'].cuda()+(1-gamma_4)*batch2['image'].cuda()\n","  mix_mask = gamma_4*batch1['mask'].cuda()+(1-gamma_4)*batch2['mask'].cuda()\n","  mix_onehot = gamma_2*batch1['onehot'].cuda()+(1-gamma_2)*batch2['onehot'].cuda()\n","  \n"," \n","  mix_batch={'image':mix_image,\n","             'mask': mix_mask,\n","             'onehot':mix_onehot,\n","             'gamma': gamma}\n","\n","  return mix_batch\n","\n","def do_cutmix(batch1, batch2,alpha=0.4):\n","    bs = len(batch1['index'])\n","    gamma = np.random.beta(alpha, alpha,bs)\n","    gamma = torch.FloatTensor(np.max(np.stack((gamma,1-gamma)),axis=0))\n","    bbx1, bby1, bbx2, bby2 = rand_bboxes((image_size,image_size), gamma.numpy())\n","\n","    cutmix_image = batch1['image'].detach().clone().cuda()\n","    cutmix_mask = batch1['mask'].detach().clone().cuda()\n","    for i in range(bs):\n","      cutmix_image[i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]] = batch2['image'][i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]]\n","      cutmix_mask[i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]] = batch2['mask'][i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]]\n","\n","    # adjust gamma to exactly match pixel ratio\n","    gamma = torch.FloatTensor(1 - ((bbx2 - bbx1) * (bby2 - bby1) / (image_size*image_size)))\n","    gamma_2 = gamma[:,None].cuda()\n","    \n","    \n","    cutmix_onehot = gamma_2*batch1['onehot'].cuda()+(1-gamma_2)*batch2['onehot'].cuda()\n","    \n","\n","    cutmix_batch = {'image': cutmix_image,\n","                    'mask': cutmix_mask,\n","                    'onehot': cutmix_onehot,\n","                    'gamma': gamma}\n","\n","    \n","    return cutmix_batch\n","  \n","def draw_batch(imbatch):\n","  bs = imbatch.shape[0]\n","  fig, axs = plt.subplots(1, bs, figsize=(30, 30))\n","  for i in range(bs):\n","    axs[i].imshow(imbatch[i,0,:,:],cmap='gray')\n","  plt.show()\n","\n","def train_augment(r):\n","    image = r['image']\n","    mask = r['mask']\n","    # if image[:2].shape != (image_size, image_size):\n","    #     image = cv2.resize(image, dsize=(image_size, image_size), interpolation=cv2.INTER_AREA)\n","\n","    if 1:\n","        for fn in np.random.choice([\n","            lambda image, mask : do_random_scale(image, mask, mag=0.20),\n","            lambda image, mask : do_random_stretch_y(image, mask, mag=0.20),\n","            lambda image, mask : do_random_stretch_x(image, mask, mag=0.20),\n","            lambda image, mask : do_random_shift(image, mask, mag=int(0.20*image_size)),\n","            lambda image, mask : (image, mask)\n","        ],1):\n","            image, mask = fn(image, mask)\n","\n","        for fn in np.random.choice([\n","            lambda image, mask : do_random_rotate(image, mask, mag=15),\n","            lambda image, mask : do_random_hflip(image, mask),\n","            lambda image, mask : (image, mask)\n","        ],1):\n","            image, mask = fn(image, mask)\n","\n","        # ------------------------\n","        for fn in np.random.choice([\n","            lambda image : do_random_intensity_shift_contast(image, mag=[0.5,0.5]),\n","            lambda image : do_random_noise(image, mag=0.05),\n","            lambda image : do_random_guassian_blur(image),\n","            lambda image : do_random_blurout(image, size=0.25, num_cut=2),\n","            #lambda image : do_random_clahe(image),\n","            #lambda image : do_histogram_norm(image),\n","            lambda image : image,\n","        ],1):\n","            image = fn(image)\n","\n","    r['image'] = image\n","    r['mask'] = mask\n","    return r\n","#----------------\n","\n","\n","def do_valid(net, valid_loader):\n","\n","    valid_probability = []\n","    valid_truth = []\n","    valid_num = 0\n","\n","    net.eval()\n","    start_timer = timer()\n","    for t, batch in enumerate(valid_loader):\n","        batch_size = len(batch['index'])\n","        image = batch['image'].cuda()\n","        onehot = batch['onehot']\n","        label = onehot.argmax(-1)\n","\n","        with torch.no_grad():\n","            #with amp.autocast():\n","                logit,mask = data_parallel(net,image)\n","                probability = F.softmax(logit,-1)\n","\n","        valid_num += batch_size\n","        valid_probability.append(probability.data.cpu().numpy())\n","        valid_truth.append(label.data.cpu().numpy())\n","        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),time_to_str(timer() - start_timer,'sec')),end='',flush=True)\n","\n","    assert(valid_num == len(valid_loader.dataset))\n","    #print('')\n","    #----------------------\n","    truth = np.concatenate(valid_truth)\n","    probability = np.concatenate(valid_probability)\n","    predict = probability.argsort(-1)[:,::-1]\n","\n","    loss = np_loss_cross_entropy(probability,truth)\n","    topk = (predict==truth.reshape(-1,1))\n","    acc  = topk[:, 0]\n","    topk = topk.mean(0).cumsum()\n","    acc = [acc[truth==i].mean() for i in range(num_study_label)]\n","\n","    #---\n","    map  = np_metric_map_curve_by_class(probability, truth)*(4/6)\n","\n","    return [loss, map.mean(), topk[0], topk[1]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dN-x5dmn9YOd","executionInfo":{"status":"ok","timestamp":1628429958182,"user_tz":-180,"elapsed":13516,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"86483dd4-eff0-4e48-d032-0196051619bc"},"source":["run_check_net()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ra-6c08e654.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ra-6c08e654.pth\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([2, 3, 768, 768])\n","torch.Size([2, 4])\n","torch.Size([2, 1, 48, 48])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JpHfPeEkIjfi"},"source":["FOLDS_SET=[0]\n","INITIALINITIAL_CHECKPOINTS=[None,None,None,None,None]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SonYuSirvgAc"},"source":["def run_train_mixup_cutmix():\n","    for fold in FOLDS_SET:\n","        out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","        \n","        initial_checkpoint=None\n","        if INITIAL_CHECKPOINTS[fold] is not None: \n","          initial_checkpoint = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d/checkpoint/'%fold+INITIAL_CHECKPOINTS[fold]\n","\n","        best_map = 0.3\n","        start_lr   = 0.001#1\n","        min_lr =     0.000005\n","        batch_size = 4 #14 #22\n","\n","        num_iteration = 25000\n","        iter_log    = 200\n","        iter_valid  = 200\n","        iter_save   = list(range(0, num_iteration+1, 200))\n","        a_iter_save = []\n","\n","        ## setup  ----------------------------------------\n","        for f in ['checkpoint', 'train', 'valid', 'backup']: os.makedirs(out_dir + '/' + f, exist_ok=True)\n","        # backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n","\n","        log = Logger()\n","        log.open(out_dir + '/log.train.txt', mode='a')\n","        log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n","        log.write('\\t%s\\n' % COMMON_STRING)\n","        log.write('\\texpirement = %s\\n' % EXPERIMENT)\n","        log.write('\\tout_dir  = %s\\n' % out_dir)\n","        log.write('\\n')\n","\n","        ## dataset ------------------------------------\n","        df_train, df_valid = make_fold('train-%d'%fold)\n","        train_dataset = SiimDataset(df_train, train_augment)\n","        valid_dataset = SiimDataset(df_valid, )\n","\n","        train_loader1 = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size,\n","            drop_last   = True,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            worker_init_fn=lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n","            collate_fn  = null_collate,\n","        )\n","        train_loader2 = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size,\n","            drop_last   = True,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            worker_init_fn=lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n","            collate_fn  = null_collate,\n","        )\n","        valid_loader  = DataLoader(\n","            valid_dataset,\n","            sampler = SequentialSampler(valid_dataset),\n","            batch_size  = batch_size,\n","            drop_last   = False,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            collate_fn  = null_collate,\n","        )\n","\n","        log.write('train_dataset : \\n%s\\n'%(train_dataset))\n","        log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n","        log.write('\\n')\n","\n","\n","        ## net ----------------------------------------\n","        log.write('** net setting **\\n')\n","        if is_mixed_precision:\n","            scaler = amp.GradScaler()\n","            net = AmpNet().cuda()\n","        else:\n","            net = Net().cuda()\n","\n","\n","        if initial_checkpoint is not None:\n","            f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n","            start_iteration = f['iteration']\n","            num_iteration = start_iteration + 15000\n","            start_epoch = f['epoch']\n","            state_dict  = f['state_dict']\n","            start_lr = f['lrate']\n","            best_map = f['map']\n","            net.load_state_dict(state_dict,strict=True)  #True\n","        else:\n","            start_iteration = 0\n","            start_epoch = 0\n","\n","\n","        log.write('net=%s\\n'%(type(net)))\n","        log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n","        log.write('\\n')\n","\n","        # -----------------------------------------------\n","        if 0: ##freeze\n","            for p in net.block0.backbone.parameters(): p.requires_grad = False\n","\n","\n","        #optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr), alpha=0.5, k=5)\n","        #optimizer = RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n","        optimizer = MADGRAD( filter(lambda p: p.requires_grad, net.parameters()), lr=start_lr, momentum= 0.9, weight_decay= 0, eps= 1e-06)\n","\n","\n","\n","        log.write('optimizer\\n  %s\\n'%(optimizer))\n","        log.write('\\n')\n","\n","\n","        ## start training here! ##############################################\n","        log.write('** start training here! **\\n')\n","        log.write('   fold = %d\\n'%(fold))\n","        log.write('   is_mixed_precision = %s \\n'%str(is_mixed_precision))\n","        log.write('   batch_size = %d\\n'%(batch_size))\n","        log.write('   experiment = %s\\n' % str(EXPERIMENT.split('/')[-2:]))\n","        log.write('                             |-----------VALID-------------|-----TRAIN/BATCH -----|------TIME-----\\n')\n","        log.write('rate  plateau   iter   epoch | loss    map   topk0  topk1  | loss0  loss1  loss2  |               \\n')\n","        log.write('--------------------------------------------------------------------------------------------------\\n')\n","                  #0.00000    00   0.00*   0.00 | 0.000  0.000  0.000  0.000  | 0.000  0.000  0.000  |  0 hr 00 min\n","\n","        def message(mode='print'):\n","            if mode==('print'):\n","                asterisk = ' '\n","                loss = batch_loss\n","            if mode==('log'):\n","                asterisk = '*' if iteration in a_iter_save else ' '\n","                loss = train_loss\n","\n","            text = \\\n","                '%0.5f  %-7d %5.3f%s %4.2f  | '%(rate,rate_plateau, iteration/10000, asterisk, epoch,) +\\\n","                '%4.3f  %4.3f  %4.3f  %4.3f  | '%(*valid_loss,) +\\\n","                '%4.3f  %4.3f  %4.3f  | '%(*loss,) +\\\n","                '%s' % (time_to_str(timer() - start_timer,'min'))\n","\n","            return text\n","\n","        #----\n","        valid_loss = np.zeros(4,np.float32)\n","        train_loss = np.zeros(3,np.float32)\n","        batch_loss = np.zeros_like(train_loss)\n","        sum_train_loss = np.zeros_like(train_loss)\n","        sum_train = 0\n","        loss0 = torch.FloatTensor([0]).cuda().sum()\n","        loss1 = torch.FloatTensor([0]).cuda().sum()\n","        loss2 = torch.FloatTensor([0]).cuda().sum()\n","\n","\n","        start_timer = timer()\n","        iteration = start_iteration\n","        epoch = start_epoch\n","        rate = start_lr\n","        rate_plateau = 0\n","\n","        while  iteration < num_iteration:\n","\n","            if (rate<min_lr): break\n","            it_loader2 = iter(train_loader2)\n","\n","            for t, batch1 in enumerate(train_loader1):\n","\n","                if (iteration % iter_valid == 0):\n","\n","                        valid_loss = do_valid(net, valid_loader)\n","\n","                        if best_map < valid_loss[1]:\n","\n","                          best_map = valid_loss[1]\n","                          a_iter_save.append(iteration)\n","                          rate_plateau=0\n","                          torch.save({\n","                            'state_dict': net.state_dict(),\n","                            'iteration': iteration,\n","                            'epoch': epoch,\n","                            'lrate': rate,\n","                            'map':best_map}, out_dir + '/checkpoint/best_model.pth')\n","                          \n","                        else:\n","                          rate_plateau=rate_plateau+1\n","\n","\n","                if (iteration % iter_log == 0):\n","                  print('\\r', end='', flush=True)\n","                  log.write(message(mode='log') + '\\n')\n","\n","\n","                # learning rate schduler ------------\n","                rate = get_learning_rate(optimizer)\n","\n","                if (rate_plateau>MAX_LR_PLATEAU):\n","                  rate_plateau=0\n","                  rate = rate*LR_FACTOR\n","                  best_model_pth = out_dir+'/checkpoint/best_model.pth'\n","                  f = torch.load(best_model_pth, map_location=lambda storage, loc: storage)\n","                  state_dict  = f['state_dict']\n","                  iteration = f['iteration']\n","                  epoch = f['epoch']\n","                  net.load_state_dict(state_dict,strict=True)\n","                  del optimizer\n","                  optimizer = MADGRAD( filter(lambda p: p.requires_grad, net.parameters()), lr=rate, momentum= 0.9, weight_decay= 0, eps= 1e-06)\n","                  break\n","\n","                # mixup cutmix--------------\n","              \n","                with torch.no_grad():\n","                  prob = np.random.rand()\n","                  if prob<PROBS[0]:\n","                    batch2 = next(it_loader2)\n","                    mix_batch = do_mixup(batch1,batch2)\n","                  elif prob>=PROBS[0] and prob<PROBS[0]+PROBS[1]:\n","                    batch2 = next(it_loader2)\n","                    mix_batch = do_cutmix(batch1,batch2)\n","                  else:\n","                    mix_batch = {'image' :batch1['image'].cuda(),\n","                                 'mask'  :batch1['mask'].cuda(),\n","                                 'onehot':batch1['onehot'].cuda()}\n","\n","\n","                # one iteration update  -------------\n","                batch_size = len(batch1['index'])\n","                image = mix_batch['image']\n","                truth_mask = mix_batch['mask']\n","                truth_mask = F.interpolate(truth_mask, size=MASK_SIZE, mode='bilinear', align_corners=False)\n","                onehot = mix_batch['onehot']\n","                label = onehot.argmax(-1)\n","\n","                #----\n","                net.train()\n","                optimizer.zero_grad()\n","\n","                if is_mixed_precision:\n","                    with amp.autocast():\n","                        logit,mask = data_parallel(net, image)\n","                        loss0 = F.cross_entropy(logit, label)\n","                        loss1 = L1_FACTOR*F.binary_cross_entropy_with_logits(mask, truth_mask)\n","                        loss2 = loss0 + loss1\n","\n","                    #scaler.scale(loss0).backward()\n","                    #scaler.scale(loss1).backward()\n","                    scaler.scale(loss0+loss1).backward()\n","                    scaler.unscale_(optimizer)\n","                    #torch.nn.utils.clip_grad_norm_(net.parameters(), 2)\n","                    scaler.step(optimizer)\n","                    scaler.update()\n","\n","\n","                else :\n","                    assert(False)\n","                    print('fp32')\n","                    logit, mask = data_parallel(net, image)\n","                    loss0 = F.cross_entropy(logit, label)\n","                    loss1 = F.binary_cross_entropy_with_logits(mask, truth_mask.shape)\n","\n","                    (loss0+loss1).backward()\n","                    optimizer.step()\n","\n","\n","                # print statistics  --------\n","                epoch += 1 / len(train_loader1)\n","                iteration += 1\n","\n","                batch_loss = np.array([loss0.item(), loss1.item(), loss2.item()])\n","                sum_train_loss += batch_loss\n","                sum_train += 1\n","                if iteration % 100 == 0:\n","                    train_loss = sum_train_loss / (sum_train + 1e-12)\n","                    sum_train_loss[...] = 0\n","                    sum_train = 0\n","\n","                print('\\r', end='', flush=True)\n","                print(message(mode='print'), end='', flush=True)\n","\n","\n","        log.write('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_7GTDVDz3Io","executionInfo":{"status":"ok","timestamp":1628465479191,"user_tz":-180,"elapsed":35501307,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"0c72347f-78f6-402c-e9a0-6eadef78a482"},"source":["run_train_mixup_cutmix()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","--- [START 2021-08-08_13-36-33] ----------------------------------------------------------------\n","\n","\t@common.py:  \n","\tpytorch\n","\t\tseed = 1628429798\n","\t\ttorch.__version__              = 1.9.0+cu102\n","\t\ttorch.version.cuda             = 10.2\n","\t\ttorch.backends.cudnn.version() = 7605\n","\t\tos['CUDA_VISIBLE_DEVICES']     = 0\n","\t\ttorch.cuda.device_count()      = 1\n","\t\ttorch.cuda.get_device_properties() = (name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n","\n","\n","\texpirement = SZ768_B7_NEWTEST\n","\tout_dir  = /content/drive/My Drive/kaggle/covid19-det/output/SZ768_B7_NEWTEST/fold0\n","\n","train_dataset : \n","\tlen = 4980\n","\tdf  = (4980, 10)\n","\tlabel distribution\n","\t\t 0     Negative for Pneumonia:  1366 (0.2743)\n","\t\t 1         Typical Appearance:  2367 (0.4753)\n","\t\t 2   Indeterminate Appearance:   864 (0.1735)\n","\t\t 3        Atypical Appearance:   383 (0.0769)\n","\n","valid_dataset : \n","\tlen = 1247\n","\tdf  = (1247, 10)\n","\tlabel distribution\n","\t\t 0     Negative for Pneumonia:   343 (0.2751)\n","\t\t 1         Typical Appearance:   591 (0.4739)\n","\t\t 2   Indeterminate Appearance:   218 (0.1748)\n","\t\t 3        Atypical Appearance:    95 (0.0762)\n","\n","\n","** net setting **\n","net=<class '__main__.AmpNet'>\n","\tinitial_checkpoint = None\n","\n","optimizer\n","  MADGRAD (\n","Parameter Group 0\n","    eps: 1e-06\n","    lr: 0.001\n","    momentum: 0.9\n","    weight_decay: 0\n",")\n","\n","** start training here! **\n","   fold = 0\n","   is_mixed_precision = True \n","   batch_size = 4\n","   experiment = ['SZ768_B7_NEWTEST']\n","                             |-----------VALID-------------|-----TRAIN/BATCH -----|------TIME-----\n","rate  plateau   iter   epoch | loss    map   topk0  topk1  | loss0  loss1  loss2  |               \n","--------------------------------------------------------------------------------------------------\n","0.00100  1       0.000  0.00  | 1.381  0.201  0.269  0.577  | 0.000  0.000  0.000  |  0 hr 01 min\n","0.00100  2       0.020  0.16  | 1.205  0.223  0.508  0.719  | 1.266  1.149  2.415  |  0 hr 06 min\n","0.00100  3       0.040  0.32  | 1.088  0.280  0.605  0.787  | 1.299  1.015  2.314  |  0 hr 11 min\n","0.00100  4       0.060  0.48  | 1.201  0.258  0.478  0.712  | 1.158  0.959  2.118  |  0 hr 16 min\n","0.00100  5       0.080  0.64  | 1.076  0.275  0.605  0.783  | 1.138  0.948  2.086  |  0 hr 21 min\n","0.00100  6       0.100  0.80  | 1.228  0.245  0.470  0.747  | 1.112  0.938  2.050  |  0 hr 26 min\n","0.00100  7       0.120  0.96  | 1.341  0.242  0.448  0.724  | 1.060  0.944  2.005  |  0 hr 30 min\n","0.00100  0       0.140* 1.12  | 0.953  0.322  0.634  0.791  | 1.097  0.875  1.972  |  0 hr 35 min\n","0.00100  1       0.160  1.29  | 1.111  0.294  0.561  0.763  | 1.128  0.928  2.056  |  0 hr 40 min\n","0.00100  2       0.180  1.45  | 1.032  0.306  0.609  0.784  | 1.065  0.948  2.012  |  0 hr 45 min\n","0.00100  3       0.200  1.61  | 0.978  0.306  0.632  0.789  | 1.088  0.886  1.974  |  0 hr 50 min\n","0.00100  4       0.220  1.77  | 1.025  0.299  0.581  0.780  | 1.132  0.880  2.012  |  0 hr 55 min\n","0.00100  5       0.240  1.93  | 0.969  0.316  0.631  0.798  | 1.067  0.907  1.974  |  1 hr 00 min\n","0.00100  6       0.260  2.09  | 0.970  0.321  0.629  0.796  | 1.124  0.810  1.934  |  1 hr 05 min\n","0.00100  7       0.280  2.25  | 0.933  0.322  0.642  0.821  | 1.066  0.838  1.904  |  1 hr 10 min\n","0.00100  0       0.300* 2.41  | 0.974  0.326  0.630  0.797  | 1.033  0.916  1.949  |  1 hr 15 min\n","0.00100  0       0.320* 2.57  | 0.944  0.331  0.645  0.798  | 1.070  0.839  1.909  |  1 hr 20 min\n","0.00100  0       0.340* 2.73  | 0.940  0.336  0.637  0.793  | 1.013  0.858  1.871  |  1 hr 25 min\n","0.00100  1       0.360  2.89  | 1.064  0.303  0.607  0.780  | 1.113  0.900  2.013  |  1 hr 30 min\n","0.00100  2       0.380  3.05  | 0.945  0.334  0.631  0.800  | 1.033  0.848  1.880  |  1 hr 35 min\n","0.00100  3       0.400  3.21  | 1.057  0.322  0.593  0.763  | 1.044  0.827  1.871  |  1 hr 40 min\n","0.00100  4       0.420  3.37  | 0.979  0.330  0.632  0.781  | 1.005  0.858  1.863  |  1 hr 45 min\n","0.00100  5       0.440  3.53  | 0.943  0.326  0.642  0.809  | 1.027  0.870  1.897  |  1 hr 49 min\n","0.00100  6       0.460  3.69  | 0.935  0.329  0.642  0.802  | 1.026  0.852  1.879  |  1 hr 54 min\n","0.00100  7       0.480  3.86  | 1.022  0.323  0.627  0.798  | 0.951  0.832  1.783  |  1 hr 59 min\n","0.00100  8       0.500  4.02  | 0.916  0.334  0.643  0.810  | 1.107  0.851  1.958  |  2 hr 04 min\n","0.00100  9       0.520  4.18  | 0.934  0.326  0.649  0.836  | 1.032  0.775  1.807  |  2 hr 09 min\n","0.00100  0       0.540* 4.34  | 0.915  0.337  0.652  0.833  | 0.966  0.799  1.764  |  2 hr 14 min\n","0.00100  1       0.560  4.50  | 0.929  0.336  0.638  0.808  | 0.926  0.895  1.821  |  2 hr 19 min\n","0.00100  2       0.580  4.66  | 1.010  0.322  0.602  0.785  | 1.046  0.860  1.906  |  2 hr 24 min\n","0.00100  3       0.600  4.82  | 1.216  0.305  0.505  0.765  | 1.002  0.857  1.859  |  2 hr 29 min\n","0.00100  0       0.620* 4.98  | 0.912  0.337  0.642  0.811  | 0.987  0.804  1.791  |  2 hr 34 min\n","0.00100  1       0.640  5.14  | 0.917  0.331  0.651  0.813  | 1.038  0.853  1.890  |  2 hr 39 min\n","0.00100  0       0.660* 5.30  | 0.946  0.340  0.630  0.804  | 0.953  0.840  1.793  |  2 hr 44 min\n","0.00100  1       0.680  5.46  | 0.924  0.336  0.643  0.801  | 0.966  0.770  1.736  |  2 hr 49 min\n","0.00100  2       0.700  5.62  | 1.013  0.322  0.607  0.787  | 1.032  0.838  1.869  |  2 hr 54 min\n","0.00100  0       0.720* 5.78  | 0.889  0.344  0.658  0.820  | 1.082  0.788  1.870  |  2 hr 59 min\n","0.00100  1       0.740  5.94  | 0.923  0.330  0.640  0.822  | 1.099  0.843  1.943  |  3 hr 04 min\n","0.00100  2       0.760  6.10  | 0.892  0.342  0.654  0.826  | 1.010  0.825  1.834  |  3 hr 09 min\n","0.00100  3       0.780  6.27  | 0.916  0.340  0.646  0.812  | 1.028  0.834  1.861  |  3 hr 13 min\n","0.00100  4       0.800  6.43  | 0.936  0.334  0.635  0.803  | 1.013  0.758  1.771  |  3 hr 18 min\n","0.00100  5       0.820  6.59  | 0.902  0.333  0.648  0.814  | 1.105  0.834  1.939  |  3 hr 23 min\n","0.00100  6       0.840  6.75  | 0.912  0.339  0.644  0.816  | 1.056  0.827  1.883  |  3 hr 28 min\n","0.00100  7       0.860  6.91  | 0.941  0.335  0.648  0.799  | 0.930  0.823  1.753  |  3 hr 33 min\n","0.00100  8       0.880  7.07  | 0.920  0.338  0.642  0.824  | 1.054  0.777  1.831  |  3 hr 38 min\n","0.00100  9       0.900  7.23  | 0.968  0.317  0.636  0.795  | 1.026  0.808  1.833  |  3 hr 43 min\n","0.00100  10      0.920  7.39  | 0.954  0.340  0.655  0.819  | 0.946  0.811  1.756  |  3 hr 48 min\n","0.00100  11      0.940  7.55  | 1.026  0.325  0.642  0.820  | 0.983  0.837  1.819  |  3 hr 53 min\n","0.00100  12      0.960  7.71  | 0.932  0.332  0.650  0.821  | 0.990  0.781  1.771  |  3 hr 58 min\n","0.00100  13      0.980  7.87  | 0.903  0.337  0.654  0.812  | 1.009  0.812  1.821  |  4 hr 03 min\n","0.00100  0       1.000* 8.03  | 0.900  0.345  0.642  0.819  | 0.879  0.821  1.700  |  4 hr 08 min\n","0.00100  1       1.020  8.19  | 0.909  0.344  0.645  0.805  | 0.994  0.860  1.853  |  4 hr 13 min\n","0.00100  2       1.040  8.35  | 0.941  0.334  0.651  0.826  | 0.984  0.819  1.803  |  4 hr 18 min\n","0.00100  3       1.060  8.51  | 0.949  0.333  0.637  0.820  | 1.047  0.806  1.853  |  4 hr 23 min\n","0.00100  4       1.080  8.67  | 0.900  0.331  0.654  0.826  | 0.951  0.794  1.745  |  4 hr 28 min\n","0.00100  5       1.100  8.84  | 0.937  0.339  0.635  0.808  | 0.964  0.769  1.734  |  4 hr 32 min\n","0.00100  6       1.120  9.00  | 0.885  0.341  0.657  0.834  | 0.940  0.765  1.705  |  4 hr 37 min\n","0.00100  7       1.140  9.16  | 0.932  0.339  0.634  0.816  | 1.033  0.775  1.808  |  4 hr 42 min\n","0.00100  8       1.160  9.32  | 0.915  0.337  0.653  0.813  | 1.044  0.786  1.830  |  4 hr 47 min\n","0.00100  9       1.180  9.48  | 0.930  0.332  0.651  0.818  | 0.921  0.795  1.716  |  4 hr 52 min\n","0.00100  10      1.200  9.64  | 1.097  0.302  0.584  0.766  | 0.969  0.810  1.779  |  4 hr 57 min\n","0.00100  11      1.220  9.80  | 0.896  0.335  0.646  0.817  | 0.979  0.829  1.808  |  5 hr 02 min\n","0.00100  12      1.240  9.96  | 0.891  0.341  0.655  0.813  | 0.974  0.839  1.813  |  5 hr 07 min\n","0.00100  13      1.260  10.12  | 0.899  0.333  0.651  0.820  | 0.931  0.807  1.738  |  5 hr 12 min\n","0.00100  14      1.280  10.28  | 0.915  0.337  0.629  0.805  | 0.998  0.747  1.744  |  5 hr 17 min\n","0.00100  15      1.300  10.44  | 0.890  0.339  0.651  0.831  | 0.935  0.855  1.790  |  5 hr 22 min\n","0.00100  16      1.320  10.60  | 0.896  0.338  0.651  0.819  | 0.994  0.823  1.817  |  5 hr 27 min\n","0.00100  17      1.340  10.76  | 0.967  0.335  0.649  0.820  | 0.982  0.770  1.752  |  5 hr 32 min\n","0.00100  18      1.360  10.92  | 0.998  0.324  0.609  0.782  | 1.024  0.767  1.792  |  5 hr 37 min\n","0.00100  19      1.380  11.08  | 0.891  0.338  0.648  0.820  | 1.009  0.791  1.799  |  5 hr 42 min\n","0.00100  20      1.400  11.24  | 0.902  0.337  0.653  0.824  | 0.936  0.774  1.710  |  5 hr 46 min\n","0.00100  21      1.420  11.41  | 0.899  0.340  0.646  0.832  | 0.965  0.814  1.779  |  5 hr 51 min\n","0.00010  1       1.000* 8.03  | 0.900  0.345  0.642  0.819  | 0.965  0.814  1.779  |  5 hr 53 min\n","0.00010  0       1.020* 8.19  | 0.894  0.345  0.649  0.821  | 0.913  0.750  1.663  |  5 hr 58 min\n","0.00010  0       1.040* 8.35  | 0.868  0.353  0.653  0.827  | 1.023  0.757  1.780  |  6 hr 03 min\n","0.00010  1       1.060  8.51  | 0.880  0.350  0.651  0.820  | 0.961  0.783  1.745  |  6 hr 08 min\n","0.00010  2       1.080  8.67  | 0.875  0.351  0.656  0.825  | 0.889  0.785  1.675  |  6 hr 13 min\n","0.00010  0       1.100* 8.84  | 0.864  0.355  0.655  0.825  | 0.951  0.715  1.666  |  6 hr 18 min\n","0.00010  1       1.120  9.00  | 0.882  0.350  0.658  0.823  | 0.888  0.791  1.679  |  6 hr 23 min\n","0.00010  2       1.140  9.16  | 0.870  0.349  0.655  0.818  | 0.920  0.716  1.636  |  6 hr 27 min\n","0.00010  3       1.160  9.32  | 0.863  0.347  0.658  0.832  | 0.861  0.762  1.623  |  6 hr 32 min\n","0.00010  4       1.180  9.48  | 0.878  0.349  0.661  0.823  | 0.993  0.762  1.755  |  6 hr 37 min\n","0.00010  5       1.200  9.64  | 0.871  0.350  0.658  0.828  | 0.870  0.728  1.598  |  6 hr 42 min\n","0.00010  6       1.220  9.80  | 0.870  0.349  0.660  0.827  | 0.995  0.770  1.765  |  6 hr 47 min\n","0.00010  7       1.240  9.96  | 0.876  0.349  0.655  0.829  | 0.897  0.754  1.651  |  6 hr 52 min\n","0.00010  8       1.260  10.12  | 0.865  0.353  0.655  0.828  | 0.899  0.661  1.560  |  6 hr 57 min\n","0.00010  9       1.280  10.28  | 0.862  0.352  0.656  0.824  | 0.921  0.804  1.725  |  7 hr 02 min\n","0.00010  10      1.300  10.44  | 0.864  0.353  0.658  0.816  | 0.934  0.738  1.673  |  7 hr 07 min\n","0.00010  11      1.320  10.60  | 0.873  0.349  0.660  0.832  | 0.970  0.748  1.718  |  7 hr 12 min\n","0.00010  12      1.340  10.76  | 0.865  0.351  0.654  0.834  | 0.947  0.805  1.751  |  7 hr 17 min\n","0.00010  13      1.360  10.92  | 0.870  0.353  0.656  0.832  | 0.848  0.719  1.567  |  7 hr 22 min\n","0.00010  14      1.380  11.08  | 0.863  0.352  0.655  0.828  | 0.875  0.767  1.642  |  7 hr 27 min\n","0.00010  15      1.400  11.24  | 0.864  0.350  0.662  0.829  | 0.909  0.720  1.628  |  7 hr 32 min\n","0.00010  16      1.420  11.41  | 0.864  0.351  0.659  0.828  | 1.010  0.728  1.738  |  7 hr 36 min\n","0.00010  17      1.440  11.57  | 0.865  0.350  0.658  0.828  | 0.934  0.771  1.705  |  7 hr 41 min\n","0.00010  18      1.460  11.73  | 0.859  0.353  0.658  0.830  | 0.913  0.756  1.669  |  7 hr 46 min\n","0.00010  19      1.480  11.89  | 0.863  0.350  0.659  0.834  | 1.007  0.712  1.719  |  7 hr 51 min\n","0.00010  20      1.500  12.05  | 0.875  0.352  0.651  0.828  | 0.897  0.733  1.630  |  7 hr 56 min\n","0.00010  21      1.520  12.21  | 0.858  0.352  0.655  0.834  | 0.890  0.781  1.670  |  8 hr 01 min\n","0.00001  1       1.100* 8.84  | 0.864  0.355  0.655  0.825  | 0.890  0.781  1.670  |  8 hr 03 min\n","0.00001  0       1.120* 9.00  | 0.860  0.356  0.660  0.831  | 0.946  0.733  1.678  |  8 hr 07 min\n","0.00001  1       1.140  9.16  | 0.860  0.354  0.657  0.825  | 0.927  0.782  1.709  |  8 hr 12 min\n","0.00001  2       1.160  9.32  | 0.861  0.352  0.658  0.824  | 0.802  0.768  1.570  |  8 hr 17 min\n","0.00001  3       1.180  9.48  | 0.868  0.352  0.654  0.826  | 0.892  0.752  1.644  |  8 hr 22 min\n","0.00001  4       1.200  9.64  | 0.864  0.355  0.659  0.825  | 0.954  0.722  1.676  |  8 hr 27 min\n","0.00001  5       1.220  9.80  | 0.864  0.353  0.656  0.826  | 0.894  0.772  1.666  |  8 hr 32 min\n","0.00001  6       1.240  9.96  | 0.863  0.353  0.654  0.828  | 0.885  0.765  1.650  |  8 hr 37 min\n","0.00001  7       1.260  10.12  | 0.862  0.353  0.654  0.825  | 0.946  0.764  1.710  |  8 hr 42 min\n","0.00001  8       1.280  10.28  | 0.865  0.351  0.651  0.824  | 0.940  0.719  1.660  |  8 hr 47 min\n","0.00001  9       1.300  10.44  | 0.862  0.352  0.654  0.823  | 0.861  0.756  1.617  |  8 hr 52 min\n","0.00001  10      1.320  10.60  | 0.864  0.352  0.654  0.828  | 0.874  0.758  1.632  |  8 hr 57 min\n","0.00001  11      1.340  10.76  | 0.860  0.352  0.658  0.825  | 0.804  0.703  1.507  |  9 hr 02 min\n","0.00001  12      1.360  10.92  | 0.859  0.354  0.660  0.828  | 0.904  0.757  1.662  |  9 hr 07 min\n","0.00001  13      1.380  11.08  | 0.861  0.352  0.656  0.829  | 0.910  0.779  1.689  |  9 hr 12 min\n","0.00001  14      1.400  11.24  | 0.860  0.352  0.658  0.828  | 0.905  0.774  1.679  |  9 hr 17 min\n","0.00001  15      1.420  11.41  | 0.863  0.354  0.654  0.828  | 0.881  0.720  1.601  |  9 hr 22 min\n","0.00001  16      1.440  11.57  | 0.860  0.353  0.651  0.828  | 0.884  0.730  1.614  |  9 hr 26 min\n","0.00001  17      1.460  11.73  | 0.859  0.353  0.657  0.827  | 0.967  0.704  1.670  |  9 hr 31 min\n","0.00001  18      1.480  11.89  | 0.858  0.356  0.658  0.828  | 0.819  0.751  1.570  |  9 hr 36 min\n","0.00001  19      1.500  12.05  | 0.869  0.351  0.661  0.822  | 0.918  0.741  1.659  |  9 hr 41 min\n","0.00001  20      1.520  12.21  | 0.857  0.354  0.658  0.822  | 0.932  0.785  1.717  |  9 hr 46 min\n","0.00001  21      1.540  12.37  | 0.857  0.352  0.658  0.826  | 0.837  0.757  1.594  |  9 hr 51 min\n","\n"],"name":"stdout"}]}]}