{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"submit yolo by hengck23.ipynb","provenance":[{"file_id":"11qCEgqshsIilyZNW1uZ2O1I2rzvYqR9G","timestamp":1623745009911},{"file_id":"1r6fwPZUfesKm9odwVnB-UyIwzsa0KID6","timestamp":1623701113374},{"file_id":"11i35Q75Lrc9PnrlpHi5mI0aAPI7WAnKw","timestamp":1622307815280}],"collapsed_sections":[],"authorship_tag":"ABX9TyNmb7bGymhillF+C9GhkAzg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nSexlhNeWHsy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628148900986,"user_tz":-180,"elapsed":10,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"adc7c642-56e2-4dbe-ef50-0e0163e68f70"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Aug  5 07:35:01 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rMIRX_fD79N8","executionInfo":{"status":"ok","timestamp":1628148900987,"user_tz":-180,"elapsed":5,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#config consts\n","DATASET =     {'train':'train.tar.gz',\n","               'test':'test.tar.gz',\n","               'train_mask':'train_mask.tar.gz'}\n","\n","METADATA=     {'image_level':'train_image_level.csv',\n","               'study_level':'train_study_level.csv',\n","               'df_meta':'df_meta.csv',\n","               'df_fold_rand830':'df_fold_rand830.csv',\n","               'train_dup':'duplicate.txt',\n","               'sample_sub':'sample_submission.csv',\n","               'df_annotate':'df_annotate.csv',\n","               'df_meta_hw':'df_meta_hw.csv',\n","               'yolov5m':'yolov5m.pt',\n","               'yolov5x':'yolov5x.pt',\n","               'submit_0598': 'submit_0598.csv'}\n","\n","CFGMODEL_DIR_DICT = {'B3_512':'effb3-full-512-mask-v8/',\n","                     'B4_512':'effb4-full-512-mask/',\n","                     'B5_600':'effb5-600-mask/',\n","                     'B5_640':'effb5-640-mask/',\n","                     'D201_640':'d201-640-mask/',\n","                     'YOLO5_640':'custom-yolo5-640-v4/'}\n","\n","INPUT_DIR ='/content/drive/My\\ Drive/kaggle/covid19-det/input/'\n","\n","OUTPUT_DIR = {'BSL':'/content/drive/My\\ Drive/kaggle/covid19-det/output/',\n","              'NORM':'/content/drive/My Drive/kaggle/covid19-det/output/'}\n","\n","IMPORT_DIR = '/content/drive/My Drive/kaggle/covid19-det/nbs/py/'\n","\n","HENGCK_IM_DIR=IMPORT_DIR+'hengck_code/dummy_01q/'\n","HENGCK_IM_DIR_YOLO=IMPORT_DIR+'hengck_code/dummy_01a/'\n","\n","WORK_DIR='/content/'\n","\n","DATASET_DIR_DICT = {'256': INPUT_DIR+'256_jpg/',\n","                    '512': INPUT_DIR+'512_jpg/',\n","                    '600': INPUT_DIR+'600_jpg/',\n","                    '640': INPUT_DIR+'640_jpg/'}\n","\n","EXPERIMENT='SZ640_YOLO_TEST3'\n","EXPERIMENT_DIR = OUTPUT_DIR['BSL'] + EXPERIMENT+'/'\n","CFGMODEL_DIR = CFGMODEL_DIR_DICT['YOLO5_640']\n","MASK_SIZE=(40,40)\n","DATASET_DIR = DATASET_DIR_DICT['640']\n","METADATA_DIR = INPUT_DIR+'metadata/'\n","FOLDS_SET=[0,1,2,3,4]\n","ENSEMBLE_CSV='/ensyolo_t3.csv'\n","INITIAL_CHECKPOINTS=['best_model.pth','best_model.pth','best_model.pth','best_model.pth','best_model.pth']"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"lgTs_sntmBhY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628148936766,"user_tz":-180,"elapsed":35784,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"f6ab0166-0f73-4083-9999-97ea01b27b96"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xYx0Py_qWSqK","executionInfo":{"status":"ok","timestamp":1628148936766,"user_tz":-180,"elapsed":7,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["if 0:\n","  !cp -r {OUTPUT_DIR['BSL']+'mpack'} '/content'\n","  !tar zcvf mpack.tar.gz '/content/mpack/'\n","  !cp /content/mpack.tar.gz {OUTPUT_DIR['BSL']}"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejcvBA62Ppy7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628148965681,"user_tz":-180,"elapsed":28920,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"47d4bf49-2fb1-4602-9156-8114f0a5cb44"},"source":["def copy_dataset(ds_dict, ds_dir, work_dir):\n","  for record in ds_dict:\n","    print('copy', ds_dir+ds_dict[record], ' to', work_dir)\n","    !cp {ds_dir+ds_dict[record]} {work_dir}\n","    print('mkdir',work_dir+record)\n","    !mkdir {work_dir+record}\n","    print ('tar -xzf',work_dir+ds_dict[record],'-C',work_dir+record)\n","    !tar -xzf  {work_dir+ds_dict[record]} -C {work_dir+record}\n","    print ('rm ',work_dir+ds_dict[record])\n","    !rm {work_dir+ds_dict[record]}\n","def copy_metadata(md_dict,md_dir,work_dir):\n","  for record in md_dict:\n","    print('copy ', md_dir+md_dict[record],' to ',work_dir)\n","    !cp {md_dir+md_dict[record]} {work_dir}\n","\n","copy_dataset(DATASET,DATASET_DIR, WORK_DIR)\n","copy_metadata(METADATA,METADATA_DIR,WORK_DIR)\n","!ls /content/"],"execution_count":5,"outputs":[{"output_type":"stream","text":["copy /content/drive/My\\ Drive/kaggle/covid19-det/input/640_jpg/train.tar.gz  to /content/\n","mkdir /content/train\n","tar -xzf /content/train.tar.gz -C /content/train\n","rm  /content/train.tar.gz\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/640_jpg/test.tar.gz  to /content/\n","mkdir /content/test\n","tar -xzf /content/test.tar.gz -C /content/test\n","rm  /content/test.tar.gz\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/640_jpg/train_mask.tar.gz  to /content/\n","mkdir /content/train_mask\n","tar -xzf /content/train_mask.tar.gz -C /content/train_mask\n","rm  /content/train_mask.tar.gz\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/train_image_level.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/train_study_level.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_meta.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_fold_rand830.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/duplicate.txt  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/sample_submission.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_annotate.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_meta_hw.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/yolov5m.pt  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/yolov5x.pt  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/submit_0598.csv  to  /content/\n","df_annotate.csv      sample_data\t    train_mask\n","df_fold_rand830.csv  sample_submission.csv  train_study_level.csv\n","df_meta.csv\t     submit_0598.csv\t    yolov5m.pt\n","df_meta_hw.csv\t     test\t\t    yolov5x.pt\n","drive\t\t     train\n","duplicate.txt\t     train_image_level.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"00xbF6PUOJqd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628149002268,"user_tz":-180,"elapsed":36599,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"3c4f4de3-d07c-4abd-fe36-8b85e845a690"},"source":["import sys\n","sys.path.append(HENGCK_IM_DIR_YOLO)\n","sys.path.append(HENGCK_IM_DIR_YOLO+CFGMODEL_DIR)\n","\n","!pip install pydicom\n","!pip install ensemble-boxes\n","#!pip install madgrad\n","#!pip install timm\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","from siim import *\n","\n","\n","from model import *\n","from dataset import *\n","from common import *\n","from ensemble_boxes import *\n","from tqdm import tqdm"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting pydicom\n","  Downloading pydicom-2.1.2-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 10.8 MB/s \n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.1.2\n","Collecting ensemble-boxes\n","  Downloading ensemble_boxes-1.0.6-py3-none-any.whl (20 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from ensemble-boxes) (0.51.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ensemble-boxes) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ensemble-boxes) (1.1.5)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->ensemble-boxes) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->ensemble-boxes) (57.2.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ensemble-boxes) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ensemble-boxes) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ensemble-boxes) (1.15.0)\n","Installing collected packages: ensemble-boxes\n","Successfully installed ensemble-boxes-1.0.6\n","matplotlib.get_backend :  module://ipykernel.pylab.backend_inline\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/My Drive/kaggle/covid19-det/nbs/py/hengck_code/dummy_01a/siim/map_boxes/compute_overlap.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"alxXQsMZnT9P","executionInfo":{"status":"ok","timestamp":1628149002746,"user_tz":-180,"elapsed":493,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def make_df_image(df_valid, detection):\n","    df_image = pd.DataFrame()\n","    df_image.loc[:,'id'] = df_valid.image + '_image'\n","    #df_image.loc[:, 'PredictionString']=''\n","\n","    predict_string = []\n","    for i,det in enumerate(detection):\n","        d = df_valid.iloc[i]\n","\n","        s = ''\n","        for x0, y0, x1, y1, c in det:\n","            x0 = int(x0/image_size*d.width )\n","            y0 = int(y0/image_size*d.height)\n","            x1 = int(x1/image_size*d.width )\n","            y1 = int(y1/image_size*d.height)\n","\n","            if x0<0: x0=0\n","            if y0<0: y0=0\n","            if x1<0: x1=0\n","            if y1<0: y1=0\n","\n","            if x0>d.width: x0=d.width\n","            if y0>d.height: y0=d.height\n","            if x1>d.width: x1=d.width\n","            if y1>d.height: y1=d.height\n","\n","            if (x1-x0)*(y1-y0) == 0.0: continue\n","\n","            s += ' opacity %0.5f %4d %4d %4d %4d'%(c,x0,y0,x1,y1)\n","\n","        predict_string.append(s)\n","\n","    df_image.loc[:, 'PredictionString'] = predict_string\n","    #df_image = df_image[['id','PredictionString']]\n","    return df_image\n","\n","\n","#---------------------------------------------------------\n","\n","\n","def do_predict(net, valid_loader, tta=[]): #flip\n","\n","    valid_detection = []\n","    valid_num = 0\n","\n","    start_timer = timer()\n","    for t, batch in enumerate(valid_loader):\n","        batch_size = len(batch['index'])\n","        image  = batch['image'].cuda()\n","\n","        onehot = batch['onehot']\n","        label  = onehot.argmax(-1)\n","        mask   = batch['mask']\n","\n","        #<todo> TTA\n","        net.eval()\n","        with torch.no_grad():\n","            predict = net(image)\n","            predict = infer_prediction(predict)\n","            predict_flat = pyramid_to_flat(predict)\n","\n","            detection = do_non_max_suppression(\n","                    predict_flat,\n","                    nms_objectness_threshold=0.0001,\n","                    nms_iou_threshold=0.5,\n","                    nms_pre_max_num=500,\n","                    nms_post_max_num=25,\n","            )\n","\n","            #debug ------------------------------------------------------------------\n","            if 0:\n","                image = image.permute(0, 2, 3, 1).contiguous()\n","                image = image.data.cpu().numpy()\n","                image = (image * 255).astype(np.uint8)\n","\n","                mask = mask.permute(0, 2, 3, 1).repeat(1, 1, 1, 3)\n","                mask = mask.data.cpu().numpy()\n","                mask = (mask * 255).astype(np.uint8)\n","\n","                for b in range(batch_size):\n","                    image_show('image', image[b], resize=1)\n","                    image_show('mask', mask[b], resize=1)\n","\n","                    overlay = mask[b].copy()\n","                    d = detection[b]\n","                    for x0,y0,x1,y1,s in d:\n","                        x0 = int(x0)\n","                        y0 = int(y0)\n","                        x1 = int(x1)\n","                        y1 = int(y1)\n","                        if s>0.5:\n","                            cv2.rectangle(overlay, (x0, y0), (x1, y1), (0, 0, 255), 3)\n","                            draw_shadow_text(overlay, '%0.4f'%s, (x0,y0+15), 0.8, (255,255,255),1)\n","                        else:\n","                            cv2.rectangle(overlay, (x0, y0), (x1, y1), (0, 255, 0), 1)\n","\n","                    image_show('overlay', overlay, resize=1)\n","                    cv2.waitKey(0)\n","\n","\n","        valid_num += batch_size\n","        valid_detection.extend(detection)\n","        print('\\r %8d / %d  %s' % (valid_num, len(valid_loader.dataset), time_to_str(timer() - start_timer, 'sec')),\n","              end='', flush=True)\n","\n","    assert(valid_num == len(valid_loader.dataset))\n","    print('')\n","\n","    detection = valid_detection\n","    return detection\n","\n","def run_submit():\n","\n","    for fold in FOLDS_SET:\n","        out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","        initial_checkpoint =out_dir + '/checkpoint/'+INITIAL_CHECKPOINTS[fold] # None #\n","            \n","\n","        if 1:\n","\n","            ## setup  ----------------------------------------\n","            #mode = 'local'\n","            mode = 'remote'\n","\n","            submit_dir = out_dir + '/valid/%s'%(mode)\n","            os.makedirs(submit_dir, exist_ok=True)\n","\n","            log = Logger()\n","            log.open(out_dir + '/log.submit.txt', mode='a')\n","            log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n","            log.write('\\t%s\\n' % COMMON_STRING)\n","            log.write('\\n')\n","\n","            #\n","            ## dataset ------------------------------------\n","\n","            if 'remote' in mode: #1263\n","                df_annotate, df_valid = make_fold('test')\n","\n","            if 'local' in mode: #1276 #1256\n","                df_annotate, df_train, df_valid = make_fold('train-%d' % fold)\n","                #df_valid = df_train\n","\n","            valid_dataset = SiimDataset(df_annotate, df_valid)\n","            valid_loader  = DataLoader(\n","                valid_dataset,\n","                sampler = SequentialSampler(valid_dataset),\n","                batch_size  = 4,#128, #\n","                drop_last   = False,\n","                num_workers = 0,\n","                pin_memory  = True,\n","                collate_fn  = null_collate,\n","            )\n","            log.write('mode : %s\\n'%(mode))\n","            log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n","\n","            ## net ----------------------------------------\n","            if 1:\n","                net = Net().cuda()\n","                net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n","\n","                #---\n","                start_timer = timer()\n","                detection = do_predict(net, valid_loader)\n","                log.write('time %s \\n' % time_to_str(timer() - start_timer, 'min'))\n","                log.write('detection %d \\n' % len(detection))\n","\n","                write_pickle_to_file(submit_dir + '/detection.pickle',detection)\n","                #df_valid['study'].to_csv(submit_dir + '/study.csv', index=False)\n","                #df_valid.to_csv(submit_dir + '/df_valid.csv', index=False)\n","\n","                #write_pickle_to_file(submit_dir + '/study.pickle', df_valid.study.values)\n","                #exit(0)\n","            else:\n","                detection = read_pickle_from_file(submit_dir + '/detection.pickle')\n","                pass\n","\n","\n","            #----\n","            df_image  = make_df_image(df_valid, detection)\n","            df_submit = df_image\n","            df_submit.to_csv(submit_dir + '/submit.csv', index=False)\n","\n","            log.write('submit_dir : %s\\n' % (submit_dir))\n","            log.write('initial_checkpoint : %s\\n' % (initial_checkpoint))\n","            log.write('df_submit : %s\\n' % str(df_submit.shape))\n","            log.write('%s\\n' % str(df_submit))\n","            log.write('\\n')\n","\n","            if 'local' in mode:\n","                #exit(0)\n","\n","                #['ImageID', 'LabelName', 'Conf', 'XMin', 'XMax', 'YMin', 'YMax']\n","                df_predict = {\n","                    'ImageID':[],\n","                    'LabelName':[],\n","                    'Conf':[],\n","                    'XMin':[],\n","                    'XMax':[],\n","                    'YMin':[],\n","                    'YMax':[],\n","                }\n","                for i,det in enumerate(detection):\n","                    d = df_valid.iloc[i]\n","\n","                    for x0, y0, x1, y1, c in det:\n","                        x0 = int(x0 / image_size * d.width)\n","                        y0 = int(y0 / image_size * d.height)\n","                        x1 = int(x1 / image_size * d.width)\n","                        y1 = int(y1 / image_size * d.height)\n","\n","\n","\n","                        df_predict['ImageID'].append(d.image)\n","                        df_predict['LabelName'].append(0)\n","                        df_predict['Conf'].append(c)\n","                        df_predict['XMin'].append(x0)\n","                        df_predict['XMax'].append(x1)\n","                        df_predict['YMin'].append(y0)\n","                        df_predict['YMax'].append(y1)\n","\n","                df_predict = pd.DataFrame(df_predict)\n","                log.write('df_predict.shape : %s\\n' % str(df_predict.shape))\n","\n","\n","                #-------------------------------------------------------------------------\n","\n","                #['ImageID', 'LabelName', 'XMin', 'XMax', 'YMin', 'YMax']\n","                df_truth = {\n","                    'ImageID':[],\n","                    'LabelName':[],\n","                    'XMin':[],\n","                    'XMax':[],\n","                    'YMin':[],\n","                    'YMax':[],\n","                }\n","\n","                gb = df_annotate.groupby('image_id')\n","                for i,d in df_valid.iterrows():\n","                    g = gb.get_group(d.image)\n","\n","                    for j,f in g.iterrows():\n","                        if f.class_id==0: continue\n","                        x0 = f.x\n","                        y0 = f.y\n","                        x1 = f.x+f.w\n","                        y1 = f.y+f.h\n","                        df_truth['ImageID'].append(d.image)\n","                        df_truth['LabelName'].append(0)\n","                        df_truth['XMin'].append(x0)\n","                        df_truth['XMax'].append(x1)\n","                        df_truth['YMin'].append(y0)\n","                        df_truth['YMax'].append(y1)\n","\n","                df_truth = pd.DataFrame(df_truth)\n","                log.write('df_truth.shape : %s\\n' % str(df_truth.shape))\n","\n","                map, _ = mean_average_precision_for_boxes(\n","                    df_truth, df_predict, iou_threshold=0.5, exclude_not_in_annotations=False, verbose=True)\n","\n","                log.write('map(opacity) : %f\\n' % map)\n","                log.write('map*0.16     : %f\\n' % (map/6))\n","                log.write('\\n\\n')\n","        #exit(0)\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ytgFMNbHkpz7","executionInfo":{"status":"ok","timestamp":1628149002747,"user_tz":-180,"elapsed":5,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def run_wbf_submit(nms_objectness_threshold=0.001,nms_pre_max_num=500,iou_thr=0.55,skip_box_thr=0.001):\n","  for fold in FOLDS_SET:\n","    out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","    initial_checkpoint =out_dir + '/checkpoint/'+INITIAL_CHECKPOINTS[fold]\n","    submit_dir = out_dir + '/valid/remote'\n","    df_annotate, df_valid = make_fold('test')\n","    valid_dataset = SiimDataset(df_annotate, df_valid)\n","    valid_loader  = DataLoader(\n","                valid_dataset,\n","                sampler = SequentialSampler(valid_dataset),\n","                batch_size  = 4,#128, #\n","                drop_last   = False,\n","                num_workers = 0,\n","                pin_memory  = True,\n","                collate_fn  = null_collate,\n","            )\n","    net = Net().cuda()\n","    net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n","    df_image = pd.DataFrame()\n","    df_image.loc[:,'id'] = df_valid.image + '_image'\n","    img_i=0\n","    prediction_string=[]\n","    for t, batch in tqdm(enumerate(valid_loader)):\n","      image  = batch['image'].cuda()\n","      net.eval()\n","      with torch.no_grad():\n","        predict = net(image)\n","        predict = infer_prediction(predict)\n","        predict_flat = pyramid_to_flat(predict)\n","        batch_size = len(batch['index'])\n","        for b in range(batch_size):\n","          d = df_valid.iloc[img_i]\n","          #print(d.image,batch['d'][b]['image'],'\\n')\n","          img_i=img_i+1\n","          p=predict_flat[b]\n","          i = p[..., 4] > nms_objectness_threshold\n","          p=p[i]\n","          num=len(p)\n","          if num==0:\n","            prediction_string.append('none 1 0 0 1 1')\n","            continue\n","          boxes = xywh2xyxy(p[:, :4])\n","          scores = p[:,4]\n","          if num > nms_pre_max_num:  # excess boxes\n","            i = scores.argsort(descending=True)[:nms_pre_max_num]  # sort by confidence\n","            boxes = boxes[i]\n","            scores = scores[i]\n","          labels = torch.zeros_like(scores)\n","          wbf_boxes, wbf_scores, wbf_labels = weighted_boxes_fusion([(boxes/image_size).tolist()], [scores.tolist()], [labels.tolist()],\n","                                                                    weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","          det = np.concatenate([wbf_boxes,wbf_scores[:,None]],-1)\n","          s=''\n","          for x0, y0, x1, y1, c in det:\n","            x0 = int(round(x0*d.width) )\n","            y0 = int(round(y0*d.height))\n","            x1 = int(round(x1*d.width))\n","            y1 = int(round(y1*d.height))\n","            s += ' opacity %0.5f %4d %4d %4d %4d'%(c,x0,y0,x1,y1)\n","          prediction_string.append(s)\n","    df_image.loc[:, 'PredictionString'] = prediction_string\n","    df_image.to_csv(submit_dir + '/wbf_sub_v2.csv', index=False)\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTvnKVkBSUrp","executionInfo":{"status":"ok","timestamp":1628149003119,"user_tz":-180,"elapsed":376,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def run_wbf_cv(nms_objectness_threshold=0.001,nms_pre_max_num=500,iou_thr=0.55,skip_box_thr=0.001):\n","  log = Logger()\n","  log.open(OUTPUT_DIR['NORM']+EXPERIMENT + '/log.wbf_cv.txt', mode='a')\n","  for fold in FOLDS_SET:\n","    out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","    initial_checkpoint =out_dir + '/checkpoint/'+INITIAL_CHECKPOINTS[fold]\n","    submit_dir = out_dir + '/valid/local'\n","    os.makedirs(submit_dir, exist_ok=True)\n","    df_annotate, df_train, df_valid = make_fold('train-%d' % fold)\n","    valid_dataset = SiimDataset(df_annotate, df_valid)\n","    valid_loader  = DataLoader(\n","                valid_dataset,\n","                sampler = SequentialSampler(valid_dataset),\n","                batch_size  = 4,#128, #\n","                drop_last   = False,\n","                num_workers = 0,\n","                pin_memory  = True,\n","                collate_fn  = null_collate,\n","            )\n","    net = Net().cuda()\n","    net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n","    df_image = pd.DataFrame()\n","    df_image.loc[:,'id'] = df_valid.image + '_image'\n","    img_i=0\n","    prediction_string=[]\n","    df_predict = {\n","                    'ImageID':[],\n","                    'LabelName':[],\n","                    'Conf':[],\n","                    'XMin':[],\n","                    'XMax':[],\n","                    'YMin':[],\n","                    'YMax':[],\n","                }\n","    for t, batch in enumerate(valid_loader):\n","      image  = batch['image'].cuda()\n","      net.eval()\n","      with torch.no_grad():\n","        predict = net(image)\n","        predict = infer_prediction(predict)\n","        predict_flat = pyramid_to_flat(predict)\n","        batch_size = len(batch['index'])\n","        for b in range(batch_size):\n","          d = df_valid.iloc[img_i]\n","          #print(d.image,batch['d'][b]['image'],'\\n')\n","          img_i=img_i+1\n","          p=predict_flat[b]\n","          i = p[..., 4] > nms_objectness_threshold\n","          p=p[i]\n","          num=len(p)\n","          if num==0:\n","            prediction_string.append('none 1 0 0 1 1')\n","            continue\n","          boxes = xywh2xyxy(p[:, :4])\n","          scores = p[:,4]\n","          if num > nms_pre_max_num:  # excess boxes\n","            i = scores.argsort(descending=True)[:nms_pre_max_num]  # sort by confidence\n","            boxes = boxes[i]\n","            scores = scores[i]\n","          labels = torch.zeros_like(scores)\n","\n","          a_boxes = [(boxes/image_size).tolist()]\n","          a_scores = [scores.tolist()]\n","          a_labels = [labels.tolist()]\n","\n","          wbf_boxes, wbf_scores, wbf_labels = weighted_boxes_fusion(a_boxes,a_scores,a_labels,weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","          nms_boxes, nms_scores, nms_labels = nms(a_boxes,a_scores,a_labels, weights=None, iou_thr=iou_thr)\n","          soft_nms_boxes, soft_nms_scores, soft_nms_labels = soft_nms(a_boxes,a_scores,a_labels, weights=None,iou_thr=iou_thr, sigma=0.1, thresh=skip_box_thr)\n","          nmw_boxes, nmw_scores, nmw_labels = non_maximum_weighted(a_boxes,a_scores,a_labels,weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","\n","          final_boxes, final_scores, final_labels = weighted_boxes_fusion([wbf_boxes,nms_boxes,soft_nms_boxes,nmw_boxes],\\\n","                                                  [wbf_scores, nms_scores,soft_nms_scores,nmw_scores],\\\n","                                                  [wbf_labels,nms_labels,soft_nms_labels,nmw_labels],\\\n","                                                  weights=[1,1,1,1], iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","\n","          det = np.concatenate([final_boxes,final_scores[:,None]],-1)\n","          s=''\n","          for x0, y0, x1, y1, c in det:\n","            x0 = int(round(x0*d.width) )\n","            y0 = int(round(y0*d.height))\n","            x1 = int(round(x1*d.width))\n","            y1 = int(round(y1*d.height))\n","            s += ' opacity %0.5f %4d %4d %4d %4d'%(c,x0,y0,x1,y1)\n","            df_predict['ImageID'].append(d.image)\n","            df_predict['LabelName'].append(0)\n","            df_predict['Conf'].append(c)\n","            df_predict['XMin'].append(x0)\n","            df_predict['XMax'].append(x1)\n","            df_predict['YMin'].append(y0)\n","            df_predict['YMax'].append(y1)\n","          prediction_string.append(s)\n","    df_image.loc[:, 'PredictionString'] = prediction_string\n","    df_image.to_csv(submit_dir + '/wbf_cv_v2.csv', index=False)\n","    df_predict = pd.DataFrame(df_predict)\n","    print('df_predict.shape : %s\\n' % str(df_predict.shape))\n","\n","    df_truth = {\n","                    'ImageID':[],\n","                    'LabelName':[],\n","                    'XMin':[],\n","                    'XMax':[],\n","                    'YMin':[],\n","                    'YMax':[],\n","                }\n","\n","    gb = df_annotate.groupby('image_id')\n","    for i,d in df_valid.iterrows():\n","      g = gb.get_group(d.image)\n","      for j,f in g.iterrows():\n","        if f.class_id==0: continue\n","        x0 = f.x\n","        y0 = f.y\n","        x1 = f.x+f.w\n","        y1 = f.y+f.h\n","        df_truth['ImageID'].append(d.image)\n","        df_truth['LabelName'].append(0)\n","        df_truth['XMin'].append(x0)\n","        df_truth['XMax'].append(x1)\n","        df_truth['YMin'].append(y0)\n","        df_truth['YMax'].append(y1)\n","\n","    df_truth = pd.DataFrame(df_truth)\n","    print('df_truth.shape : %s\\n' % str(df_truth.shape))\n","\n","    map, _ = mean_average_precision_for_boxes(df_truth, df_predict, iou_threshold=0.5, exclude_not_in_annotations=False, verbose=False)\n","\n","    log_str = f'f{fold}; map: {map}; map/6 {map/6}; pre_max: {nms_pre_max_num}; o/b_thr: {skip_box_thr}; w_thr: {iou_thr};\\n'\n","\n","    log.write(log_str)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZ1AO2WC-9ng","executionInfo":{"status":"ok","timestamp":1628149003120,"user_tz":-180,"elapsed":5,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def run_ensemble_submit():\n","\n","    for fold in FOLDS_SET:\n","        out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","        initial_checkpoint =out_dir + '/checkpoint/'+INITIAL_CHECKPOINTS[fold] # None #\n","            \n","        if 1:\n","            ## setup  ----------------------------------------\n","            #mode = 'local'\n","            mode = 'remote'\n","\n","            submit_dir = out_dir + '/valid/%s'%(mode)\n","            os.makedirs(submit_dir, exist_ok=True)\n","\n","            log = Logger()\n","            log.open(out_dir + '/log.submit.txt', mode='a')\n","            log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n","            log.write('\\t%s\\n' % COMMON_STRING)\n","            log.write('\\n')\n","\n","            #\n","            ## dataset ------------------------------------\n","\n","            if 'remote' in mode: #1263\n","                df_annotate, df_valid = make_fold('test')\n","\n","\n","            valid_dataset = SiimDataset(df_annotate, df_valid)\n","            valid_loader  = DataLoader(\n","                valid_dataset,\n","                sampler = SequentialSampler(valid_dataset),\n","                batch_size  = 4,#128, #\n","                drop_last   = False,\n","                num_workers = 0,\n","                pin_memory  = True,\n","                collate_fn  = null_collate,\n","            )\n","            log.write('mode : %s\\n'%(mode))\n","            log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n","\n","            ## net ----------------------------------------\n","            if 1:\n","                net = Net().cuda()\n","                net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n","\n","                #---\n","                start_timer = timer()\n","                detection = do_predict(net, valid_loader)\n","                log.write('time %s \\n' % time_to_str(timer() - start_timer, 'min'))\n","                log.write('detection %d \\n' % len(detection))\n","\n","                write_pickle_to_file(submit_dir + '/detection.pickle',detection)\n","                #df_valid['study'].to_csv(submit_dir + '/study.csv', index=False)\n","                #df_valid.to_csv(submit_dir + '/df_valid.csv', index=False)\n","\n","                #write_pickle_to_file(submit_dir + '/study.pickle', df_valid.study.values)\n","                #exit(0)\n","            else:\n","                detection = read_pickle_from_file(submit_dir + '/detection.pickle')\n","                pass\n","\n","\n","            #----\n","            df_image  = make_df_image(df_valid, detection)\n","            df_submit = df_image\n","            if (fold==FOLDS_SET[0]):\n","              df_ens_submit = df_submit.copy()\n","            else:\n","              df_ens_submit['PredictionString']+=(' '+df_submit['PredictionString'])\n","            df_submit.to_csv(submit_dir + '/submit.csv', index=False)\n","\n","            log.write('submit_dir : %s\\n' % (submit_dir))\n","            log.write('initial_checkpoint : t%s\\n' % (initial_checkpoint))\n","            log.write('df_submit : %s\\n' % str(df_submit.shape))\n","            log.write('%s\\n' % str(df_submit))\n","            log.write('\\n')\n","    df_ens_submit.to_csv(OUTPUT_DIR['NORM']+EXPERIMENT+ENSEMBLE_CSV,index=False)    "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bq44f0xqHuBv","executionInfo":{"status":"ok","timestamp":1628149003120,"user_tz":-180,"elapsed":4,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def solve_bbox_problems(bbox_v, scores_v, labels_v):\n","    \"\"\" \n","    Solves problems in the \"ensemble-boxes\" way \n","    \"\"\"\n","    \n","    to_remove = np.zeros(bbox_v.shape[0], dtype=np.bool)\n","    for i in range(bbox_v.shape[0]):\n","        x1, y1, x2, y2 = bbox_v[i]\n","        \n","        if x2 < x1:\n","#             warnings.warn('X2 < X1 value in box. Swap them.')\n","            x1, x2 = x2, x1\n","        if y2 < y1:\n","#             warnings.warn('Y2 < Y1 value in box. Swap them.')\n","            y1, y2 = y2, y1\n","        if x1 < 0:\n","#             warnings.warn('X1 < 0 in box. Set it to 0.')\n","            x1 = 0\n","        if x1 > 1:\n","#             warnings.warn('X1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n","            x1 = 1\n","        if x2 < 0:\n","#             warnings.warn('X2 < 0 in box. Set it to 0.')\n","            x2 = 0\n","        if x2 > 1:\n","#             warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n","            x2 = 1\n","        if y1 < 0:\n","# # #             warnings.warn('Y1 < 0 in box. Set it to 0.')\n","            y1 = 0\n","        if y1 > 1:\n","# #             warnings.warn('Y1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n","            y1 = 1\n","        if y2 < 0:\n","#             warnings.warn('Y2 < 0 in box. Set it to 0.')\n","            y2 = 0\n","        if y2 > 1:\n","#             warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n","            y2 = 1\n","        if (x2 - x1) * (y2 - y1) == 0.0:\n","#             warnings.warn(\"Zero area box skipped: {}.\".format(box_part))\n","            to_remove[i] = True\n","    \n","        bbox_v[i] = x1, y1, x2, y2\n","    \n","    if to_remove.sum() > 0:\n","        # Hack to remove bboxes using min confidence th\n","        bbox_v[to_remove] = np.array([0.0, 0.0, 1.0, 1.0])\n","        scores_v[to_remove] = 0.0\n","        \n","    return bbox_v, scores_v, labels_v"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gel7GDMAp6iw","executionInfo":{"status":"ok","timestamp":1628149699854,"user_tz":-180,"elapsed":719,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def run_ensemble(nms_objectness_threshold=0.001,nms_pre_max_num=500,iou_thr=0.55,skip_box_thr=0.001):\n","  nets = []\n","  #sub_0598 = pd.read_csv('/content/submit_0598.csv')\n","  #sub_0598 = sub_0598.set_index('id')\n","  submit_dir =  OUTPUT_DIR['NORM']+EXPERIMENT\n","  df_annotate, df_valid = make_fold('test')\n","  valid_dataset = SiimDataset(df_annotate, df_valid)\n","  valid_loader  = DataLoader(\n","                valid_dataset,\n","                sampler = SequentialSampler(valid_dataset),\n","                batch_size  = 4,#128, #\n","                drop_last   = False,\n","                num_workers = 0,\n","                pin_memory  = True,\n","                collate_fn  = null_collate,\n","            )\n","  \n","  for fold in FOLDS_SET:\n","      out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","      initial_checkpoint =out_dir + '/checkpoint/'+INITIAL_CHECKPOINTS[fold]\n","      net = Net().cuda()\n","      net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n","      nets.append(net)\n","\n","  df_image = pd.DataFrame()\n","  df_image.loc[:,'id'] = df_valid.image + '_image'\n","  img_i=0\n","  prediction_string=[]\n","  for t, batch in enumerate(valid_loader):\n","      image  = batch['image'].cuda()\n","      batch_size = len(batch['index'])\n","      predict_flat_list=[]\n","      for net in nets:\n","          net.eval()\n","          with torch.no_grad():\n","            predict = net(image)\n","            predict = infer_prediction(predict)\n","            predict_flat = pyramid_to_flat(predict)\n","            predict_flat_list.append(predict_flat)\n","\n","      for b in range(batch_size):\n","        d = df_valid.iloc[img_i]\n","        img_i +=1\n","        boxes_list=[]\n","        scores_list=[]\n","        labels_list=[]\n","        for j in range(len(nets)):\n","                p=predict_flat_list[j][b]\n","                i = p[..., 4] > nms_objectness_threshold\n","                p=p[i]\n","                num=len(p)\n","                if num==0:\n","                  prediction_string.append('none 1 0 0 1 1')\n","                  continue\n","                boxes = xywh2xyxy(p[:, :4])\n","                scores = p[:,4]\n","                if num > nms_pre_max_num:\n","                    i = scores.argsort(descending=True)[:nms_pre_max_num]  # sort by confidence\n","                    boxes = boxes[i]\n","                    scores = scores[i]\n","\n","                labels = torch.zeros_like(scores)\n","\n","                boxes_list.append((boxes/image_size).tolist())\n","                scores_list.append(scores.tolist())\n","                labels_list.append(labels.tolist())\n","\n","        #line_0598=sub_0598.loc[[d.image+'_image']].PredictionString.values[0]\n","        #bset_0598=re.findall('opacity [+-]?\\d+\\.?\\d* [+-]?\\d+ [+-]?\\d+ [+-]?\\d+ [+-]?\\d+',line_0598)\n","        #boxes_0598=[]\n","        #scores_0598=[]\n","        #for sample in bset_0598:\n","        #  spl = sample.split(' ')\n","        #  boxes_0598.append([(int(spl[2])/d.width),\n","        #                     (int(spl[3])/d.height),\n","        #                     (int(spl[4])/d.width),\n","        #                     (int(spl[5])/d.height)])\n","        #  scores_0598.append(float(spl[1]))\n","        \n","        #labels_0598 = [0 for k in range(len(scores_0598))]\n","        #boxes_list,scores_list,labels_list = solve_bbox_problems( boxes_list,scores_list,labels_list)\n","        w = [1.0 for k in range(len(nets))]\n","        \n","        #nms_boxes, nms_scores, nms_labels = nms(boxes_list,scores_list,labels_list, weights=w, iou_thr=0.5)\n","        #wbf_boxes, wbf_scores, wbf_labels = weighted_boxes_fusion(boxes_list,scores_list,labels_list,\n","        #                                                         weights=w, iou_thr=0.575, skip_box_thr=skip_box_thr)\n","        #soft_nms_boxes, soft_nms_scores, soft_nms_labels = soft_nms(boxes_list,scores_list,labels_list, weights=w,\n","        #                                                            iou_thr=0.5, sigma=0.1, thresh=skip_box_thr)\n","        nmw_boxes, nmw_scores, nmw_labels = non_maximum_weighted(boxes_list,scores_list,labels_list,weights=w, \n","                                                                 iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","        #final_boxes, final_scores, final_labels = non_maximum_weighted([nmw_boxes,boxes_0598],\n","        #                                                               [nmw_scores,scores_0598],\n","        #                                                               [nmw_labels,labels_0598],\n","        #                                                               weights=[1,1], iou_thr=0.5, skip_box_thr=skip_box_thr)\n","        \n","        #final_boxes, final_scores, final_labels = weighted_boxes_fusion([wbf_boxes,nms_boxes,soft_nms_boxes,nmw_boxes],\\\n","        #                                          [wbf_scores, nms_scores,soft_nms_scores,nmw_scores],\\\n","        #                                          [wbf_labels,nms_labels,soft_nms_labels,nmw_labels],\\\n","        #                                         weights=[1,1,1,1], iou_thr=0.575, skip_box_thr=skip_box_thr)\n","        \n","        \n","\n","\n","            \n","        det = np.concatenate([nmw_boxes,nmw_scores[:,None]],-1)\n","        s=''\n","        for x0, y0, x1, y1, c in det:\n","            x0 = int(round(x0*d.width) )\n","            y0 = int(round(y0*d.height))\n","            x1 = int(round(x1*d.width))\n","            y1 = int(round(y1*d.height))\n","            s += ' opacity %0.5f %4d %4d %4d %4d'%(c,x0,y0,x1,y1)\n","        prediction_string.append(s)\n","\n","  df_image.loc[:, 'PredictionString'] = prediction_string\n","  df_image.to_csv(submit_dir + '/nmw_5f500_iou55.csv', index=False)\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPsvrV64Z4d1","executionInfo":{"status":"ok","timestamp":1628149003782,"user_tz":-180,"elapsed":6,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#run_submit()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD0l8wI0DK5V","executionInfo":{"status":"ok","timestamp":1628149003782,"user_tz":-180,"elapsed":4,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#run_wbf_cv()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6rYgQ_gIQIO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628150051749,"user_tz":-180,"elapsed":346993,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"aee4886c-2271-450c-9eaf-691a330e8058"},"source":["run_ensemble(nms_pre_max_num=500)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ensemble_boxes/ensemble_boxes_nmw.py:70: UserWarning: X1 < 0 in box. Set it to 0.\n","  warnings.warn('X1 < 0 in box. Set it to 0.')\n","/usr/local/lib/python3.7/dist-packages/ensemble_boxes/ensemble_boxes_nmw.py:82: UserWarning: Y1 < 0 in box. Set it to 0.\n","  warnings.warn('Y1 < 0 in box. Set it to 0.')\n","/usr/local/lib/python3.7/dist-packages/ensemble_boxes/ensemble_boxes_nmw.py:79: UserWarning: X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n","  warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n","/usr/local/lib/python3.7/dist-packages/ensemble_boxes/ensemble_boxes_nmw.py:91: UserWarning: Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n","  warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n"],"name":"stderr"}]}]}