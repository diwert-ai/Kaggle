{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2class mixup cutmix v2 hengck23 pipeline[siim].ipynb","provenance":[{"file_id":"1r6fwPZUfesKm9odwVnB-UyIwzsa0KID6","timestamp":1623701113374},{"file_id":"11i35Q75Lrc9PnrlpHi5mI0aAPI7WAnKw","timestamp":1622307815280}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMVNVhUgLj0EAk2oJQDRwpz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2XQH3OaLq1-_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627079153516,"user_tz":-180,"elapsed":390,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"711fec20-cf45-41ff-88bd-fe94c76a9352"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Fri Jul 23 22:25:53 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rMIRX_fD79N8","executionInfo":{"status":"ok","timestamp":1627079154500,"user_tz":-180,"elapsed":4,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#config consts\n","DATASET =     {'train':'train.tar.gz',\n","               'test':'test.tar.gz',\n","               'train_mask':'train_mask.tar.gz'}\n","\n","METADATA=     {'image_level':'train_image_level.csv',\n","               'study_level':'train_study_level.csv',\n","               'df_meta':'df_meta.csv',\n","               'df_fold_rand830':'df_fold_rand830.csv',\n","               'train_dup':'duplicate.txt',\n","               'sample_sub':'sample_submission.csv'}\n","\n","CFGMODEL_DIR_DICT = {'B3_512':'effb3-full-512-mask-v8/',\n","                     'B3_512_PNG': 'effb3-512-png-mask/',\n","                     'B4_512':'effb4-full-512-mask/',\n","                     'B5_600':'effb5-600-mask/',\n","                     'B5_640':'effb5-640-mask/',\n","                     'B5_640_M2': 'effb5-640-mask/',\n","                     'D121_640':'d121-640-mask/',\n","                     'D201_640':'d201-640-mask/',\n","                     'B5_640_2C':'effb5-640-mask-2c/',\n","                     'B7_768_2C':'effb7-768-mask-2c/',\n","                     }\n","\n","INPUT_DIR ='/content/drive/My\\ Drive/kaggle/covid19-det/input/'\n","\n","OUTPUT_DIR = {'BSL':'/content/drive/My\\ Drive/kaggle/covid19-det/output/',\n","              'NORM':'/content/drive/My Drive/kaggle/covid19-det/output/'}\n","\n","IMPORT_DIR = '/content/drive/My Drive/kaggle/covid19-det/nbs/py/'\n","\n","HENGCK_IM_DIR=IMPORT_DIR+'hengck_code/dummy_01q/'\n","\n","WORK_DIR='/content/'\n","\n","DATASET_DIR_DICT = {'256': INPUT_DIR+'256_jpg/',\n","                    '512': INPUT_DIR+'512_jpg/',\n","                    '512_PNG': INPUT_DIR+'512_png/',\n","                    '600': INPUT_DIR+'600_jpg/',\n","                    '640': INPUT_DIR+'640_jpg/',\n","                    '640_M2':INPUT_DIR+'640_jpg_m2/',\n","                    '768':INPUT_DIR+'768_jpg/'}\n","\n","EXPERIMENT='SZ768_2CLASS_5FOLDS'\n","EXPERIMENT_DIR = OUTPUT_DIR['BSL'] + EXPERIMENT+'/'\n","CFGMODEL_DIR = CFGMODEL_DIR_DICT['B7_768_2C']\n","MASK_SIZE=(48,48)\n","L1_FACTOR=2\n","LR_FACTOR=0.1\n","MAX_LR_PLATEAU=20\n","PROBS=[0,0] #mixup, cutmix \n","DATASET_DIR = DATASET_DIR_DICT['768']\n","METADATA_DIR = INPUT_DIR+'metadata/'\n","FOLDS_SET=[0,1,2,3,4]\n","INITIAL_CHECKPOINTS=[None for i in range(5)]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"lgTs_sntmBhY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627079173486,"user_tz":-180,"elapsed":18989,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"f18bd1f3-b8cd-4d18-f316-6c99b6c7d991"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTWvq4iJPT07","executionInfo":{"status":"ok","timestamp":1627079211750,"user_tz":-180,"elapsed":38270,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"afcdc787-88e1-43d2-e2dc-5154901bd772"},"source":["!pip install pydicom\n","!pip install madgrad\n","!pip install timm\n","\n","import sys\n","sys.path.append(HENGCK_IM_DIR)\n","sys.path.append(HENGCK_IM_DIR+CFGMODEL_DIR)\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","from common import *\n","\n","from siim import *\n","\n","# from lib.net.lookahead import *\n","# from lib.net.radam import *\n","from madgrad import MADGRAD\n","\n","from model import *\n","from dataset import *\n","\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_auc_score\n","\n","def copy_dataset(ds_dict, ds_dir, work_dir):\n","  for record in ds_dict:\n","    print('copy', ds_dir+ds_dict[record], ' to', work_dir)\n","    !cp {ds_dir+ds_dict[record]} {work_dir}\n","    print('mkdir',work_dir+record)\n","    !mkdir {work_dir+record}\n","    print ('tar -xzf',work_dir+ds_dict[record],'-C',work_dir+record)\n","    !tar -xzf  {work_dir+ds_dict[record]} -C {work_dir+record}\n","    print ('rm ',work_dir+ds_dict[record])\n","    !rm {work_dir+ds_dict[record]}\n","def copy_metadata(md_dict,md_dir,work_dir):\n","  for record in md_dict:\n","    print('copy ', md_dir+md_dict[record],' to ',work_dir)\n","    !cp {md_dir+md_dict[record]} {work_dir}\n","copy_dataset(DATASET,DATASET_DIR, WORK_DIR)\n","copy_metadata(METADATA,METADATA_DIR,WORK_DIR)\n","!ls /content/\n","!mkdir {EXPERIMENT_DIR}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting pydicom\n","  Downloading pydicom-2.1.2-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 16.6 MB/s \n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.1.2\n","Collecting madgrad\n","  Downloading madgrad-1.1-py3-none-any.whl (7.4 kB)\n","Installing collected packages: madgrad\n","Successfully installed madgrad-1.1\n","Collecting timm\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 14.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Installing collected packages: timm\n","Successfully installed timm-0.4.12\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/768_jpg/train.tar.gz  to /content/\n","mkdir /content/train\n","tar -xzf /content/train.tar.gz -C /content/train\n","rm  /content/train.tar.gz\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/768_jpg/test.tar.gz  to /content/\n","mkdir /content/test\n","tar -xzf /content/test.tar.gz -C /content/test\n","rm  /content/test.tar.gz\n","copy /content/drive/My\\ Drive/kaggle/covid19-det/input/768_jpg/train_mask.tar.gz  to /content/\n","mkdir /content/train_mask\n","tar -xzf /content/train_mask.tar.gz -C /content/train_mask\n","rm  /content/train_mask.tar.gz\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/train_image_level.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/train_study_level.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_meta.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/df_fold_rand830.csv  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/duplicate.txt  to  /content/\n","copy  /content/drive/My\\ Drive/kaggle/covid19-det/input/metadata/sample_submission.csv  to  /content/\n","df_fold_rand830.csv  sample_data\t    train_image_level.csv\n","df_meta.csv\t     sample_submission.csv  train_mask\n","drive\t\t     test\t\t    train_study_level.csv\n","duplicate.txt\t     train\n","mkdir: cannot create directory ‘/content/drive/My Drive/kaggle/covid19-det/output/SZ768_2CLASS_5FOLDS/’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fLj3jzqtQtCj","executionInfo":{"status":"ok","timestamp":1627079212337,"user_tz":-180,"elapsed":590,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#----------------\n","import torch.cuda.amp as amp\n","\n","class AmpNet(Net):\n","    @torch.cuda.amp.autocast()\n","    def forward(self,*args):\n","        return super(AmpNet, self).forward(*args)\n","\n","is_mixed_precision = True  #True #False\n","#run_check_net()\n","\n","def rand_bboxes(size, gamma):\n","    W = size[0]\n","    H = size[1]\n","    GS = gamma.shape[0]\n","    cut_rat = np.sqrt(1. - gamma)\n","    cut_w = np.int_(W * cut_rat)\n","    cut_h = np.int_(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W,size=GS)\n","    cy = np.random.randint(H,size=GS)\n","\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n"," \n","    return bbx1, bby1, bbx2, bby2\n","\n","def do_mixup(batch1,batch2,alpha=0.4):\n","  bs = len(batch1['index'])\n","  gamma = np.random.beta(alpha, alpha, bs)\n","  gamma = torch.FloatTensor(np.max(np.stack((gamma,1-gamma)),axis=0))\n","  gamma_4 = gamma[:,None,None,None].cuda()\n","  gamma_2 = gamma[:,None].cuda()\n","  gamma_1 = gamma[:].cuda()\n","\n","  mix_image = gamma_4*batch1['image'].cuda()+(1-gamma_4)*batch2['image'].cuda()\n","  mix_mask = gamma_4*batch1['mask'].cuda()+(1-gamma_4)*batch2['mask'].cuda()\n","  mix_onehot = gamma_2*batch1['onehot'].cuda()+(1-gamma_2)*batch2['onehot'].cuda()\n","  mix_none = gamma_1*batch1['none'].cuda()+(1-gamma_1)*batch2['none'].cuda()\n"," \n","  mix_batch={'image':mix_image,\n","             'mask': mix_mask,\n","             'onehot':mix_onehot,\n","             'gamma': gamma,\n","             'none': mix_none}\n","\n","  return mix_batch\n","\n","def do_cutmix(batch1, batch2,alpha=0.4):\n","    bs = len(batch1['index'])\n","    gamma = np.random.beta(alpha, alpha,bs)\n","    gamma = torch.FloatTensor(np.max(np.stack((gamma,1-gamma)),axis=0))\n","    bbx1, bby1, bbx2, bby2 = rand_bboxes((image_size,image_size), gamma.numpy())\n","\n","    cutmix_image = batch1['image'].detach().clone().cuda()\n","    cutmix_mask = batch1['mask'].detach().clone().cuda()\n","    for i in range(bs):\n","      cutmix_image[i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]] = batch2['image'][i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]]\n","      cutmix_mask[i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]] = batch2['mask'][i, :, bbx1[i]:bbx2[i], bby1[i]:bby2[i]]\n","\n","    # adjust gamma to exactly match pixel ratio\n","    gamma = torch.FloatTensor(1 - ((bbx2 - bbx1) * (bby2 - bby1) / (image_size*image_size)))\n","    gamma_2 = gamma[:,None].cuda()\n","    gamma_1 = gamma[:].cuda()\n","    \n","    cutmix_onehot = gamma_2*batch1['onehot'].cuda()+(1-gamma_2)*batch2['onehot'].cuda()\n","    cutmix_none = gamma_1*batch1['none'].cuda()+(1-gamma_1)*batch2['none'].cuda()\n","\n","    cutmix_batch = {'image': cutmix_image,\n","                    'mask': cutmix_mask,\n","                    'onehot': cutmix_onehot,\n","                    'gamma': gamma,\n","                    'none': cutmix_none}\n","\n","    \n","    return cutmix_batch\n","  \n","def draw_batch(imbatch):\n","  bs = imbatch.shape[0]\n","  fig, axs = plt.subplots(1, bs, figsize=(30, 30))\n","  for i in range(bs):\n","    axs[i].imshow(imbatch[i,0,:,:],cmap='gray')\n","  plt.show()\n","\n","#----------------\n","def train_augment(r):\n","    image = r['image']\n","    mask = r['mask']\n","    # if image[:2].shape != (image_size, image_size):\n","    #     image = cv2.resize(image, dsize=(image_size, image_size), interpolation=cv2.INTER_AREA)\n","\n","    if 1:\n","        for fn in np.random.choice([\n","            lambda image, mask : do_random_scale(image, mask, mag=0.20),\n","            lambda image, mask : do_random_stretch_y(image, mask, mag=0.20),\n","            lambda image, mask : do_random_stretch_x(image, mask, mag=0.20),\n","            lambda image, mask : do_random_shift(image, mask, mag=int(0.20*image_size)),\n","            lambda image, mask : (image, mask)\n","        ],1):\n","            image, mask = fn(image, mask)\n","\n","        for fn in np.random.choice([\n","            lambda image, mask : do_random_rotate(image, mask, mag=15),\n","            lambda image, mask : do_random_hflip(image, mask),\n","            lambda image, mask : (image, mask)\n","        ],1):\n","            image, mask = fn(image, mask)\n","\n","        # ------------------------\n","        for fn in np.random.choice([\n","            lambda image : do_random_intensity_shift_contast(image, mag=[0.5,0.5]),\n","            lambda image : do_random_noise(image, mag=0.05),\n","            lambda image : do_random_guassian_blur(image),\n","            lambda image : do_random_blurout(image, size=0.25, num_cut=2),\n","            #lambda image : do_random_clahe(image),\n","            #lambda image : do_histogram_norm(image),\n","            lambda image : image,\n","        ],1):\n","            image = fn(image)\n","\n","    r['image'] = image\n","    r['mask'] = mask\n","    return r\n","    \n","def do_valid(net, valid_loader):\n","    valid_probability = []\n","    valid_truth = []\n","    valid_num = 0\n","\n","    net.eval()\n","    start_timer = timer()\n","    for t, batch in enumerate(valid_loader):\n","        batch_size = len(batch['index'])\n","        image = batch['image'].cuda()\n","        label =  batch['none']\n","\n","        with torch.no_grad():\n","            #with amp.autocast():\n","                logit, mask = data_parallel(net,image)\n","                probability = torch.sigmoid(torch.reshape(logit,(-1,)))\n","              \n","\n","        valid_num += batch_size\n","        valid_probability.append(probability.data.cpu().numpy())\n","        valid_truth.append(label.data.cpu().numpy())\n","        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),time_to_str(timer() - start_timer,'sec')),end='',flush=True)\n","\n","    assert(valid_num == len(valid_loader.dataset))\n","    #print('')\n","    #----------------------\n","    truth = np.concatenate(valid_truth)\n","    probability = np.concatenate(valid_probability)\n","    loss = np_loss_binary_cross_entropy(probability,truth)\n","    map  = average_precision_score(truth, probability)\n","    rec = recall_score(truth, probability>0.5)\n","    acc = accuracy_score(truth,probability>0.5)\n","    auc = roc_auc_score(truth,probability)\n","    \n","    return [loss, map, rec, acc, auc]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpXp3eXIuESC","executionInfo":{"status":"ok","timestamp":1627079212337,"user_tz":-180,"elapsed":8,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#INITIAL_CHECKPOINTS=['best_model.pth' for i in range(5)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IejqWhJl4AaO","executionInfo":{"status":"ok","timestamp":1627079212338,"user_tz":-180,"elapsed":9,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"349f395e-a298-45d1-dff8-b732296c05c1"},"source":["INITIAL_CHECKPOINTS"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[None, None, None, None, None]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ea1qmKw8N4JV","executionInfo":{"status":"ok","timestamp":1627079212338,"user_tz":-180,"elapsed":8,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"dbd18a30-a4b0-42ad-eb08-bae2df3d28d5"},"source":["PROBS"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"r9UvULISzAfR","executionInfo":{"status":"ok","timestamp":1627079212339,"user_tz":-180,"elapsed":7,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["#debug\n","if 0:\n","  df_train_deb, _ = make_fold('train-0')\n","  train_dataset_deb = SiimDataset(df_train_deb, train_augment)\n","  train_loader_deb = DataLoader(\n","            train_dataset_deb,\n","            sampler = RandomSampler(train_dataset_deb),\n","            batch_size = 4,\n","            drop_last   = True,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            worker_init_fn=lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n","            collate_fn  = null_collate,\n","        )\n","  it = iter(train_loader_deb)\n","  batch1=next(it)\n","  batch2=next(it)\n","  cutmix_batch = do_cutmix(batch1,batch2)\n","  mixup_batch = do_mixup(batch1,batch2)\n","  print(np.sum(cutmix_batch['onehot'].cpu().numpy(),axis=1))\n","  print(np.sum(mixup_batch['onehot'].cpu().numpy(),axis=1))\n","  for key in ['image','mask']:\n","    draw_batch(batch1[key])\n","    draw_batch(batch2[key])\n","    draw_batch(mixup_batch[key].cpu())\n","    draw_batch(cutmix_batch[key].cpu())"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYhwvWOIorPW","executionInfo":{"status":"ok","timestamp":1627079212339,"user_tz":-180,"elapsed":6,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def ohem_loss(logit,label,threshold=0.7):\n","  loss=F.binary_cross_entropy_with_logits(torch.reshape(logit,(-1,)), label,reduction='none')\n","  mask = (loss>threshold)\n","  return  (loss*mask).sum()/(mask.sum()+EPS)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2nmfcvvwneo","executionInfo":{"status":"ok","timestamp":1627079212339,"user_tz":-180,"elapsed":6,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def ohem_loss_v2(logit,label,rate=0.5):\n","  bs = logit.size(0)\n","  loss=F.binary_cross_entropy_with_logits(torch.reshape(logit,(-1,)), label,reduction='none')\n","  ohem,_ = loss.topk(k=int(rate * bs))\n","  \n","  return ohem.mean()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"82--I0tkEvq6","executionInfo":{"status":"ok","timestamp":1627079212340,"user_tz":-180,"elapsed":7,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["FOLDS_SET=[2]\n","INITIAL_CHECKPOINTS=[None,None,'best_model.pth',None,None]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"SonYuSirvgAc","executionInfo":{"status":"ok","timestamp":1627079212667,"user_tz":-180,"elapsed":334,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["def run_train_mixup_cutmix():\n","    for fold in FOLDS_SET:\n","        out_dir = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d'%fold\n","        \n","        initial_checkpoint=None\n","        if INITIAL_CHECKPOINTS[fold] is not None: \n","          initial_checkpoint = OUTPUT_DIR['NORM']+EXPERIMENT+'/fold%d/checkpoint/'%fold+INITIAL_CHECKPOINTS[fold]\n","\n","        best_map = 0.3\n","        start_lr   = 0.001#1\n","        min_lr =     0.000005\n","        batch_size = 4 #14 #22\n","\n","        num_iteration = 20000\n","        iter_log    = 200\n","        iter_valid  = 200\n","        iter_save   = list(range(0, num_iteration+1, 200))\n","        a_iter_save = []\n","\n","        ## setup  ----------------------------------------\n","        for f in ['checkpoint', 'train', 'valid', 'backup']: os.makedirs(out_dir + '/' + f, exist_ok=True)\n","        # backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n","\n","        log = Logger()\n","        log.open(out_dir + '/log.train.txt', mode='a')\n","        log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n","        log.write('\\t%s\\n' % COMMON_STRING)\n","        log.write('\\texpirement = %s\\n' % EXPERIMENT)\n","        log.write('\\tout_dir  = %s\\n' % out_dir)\n","        log.write('\\n')\n","\n","        ## dataset ------------------------------------\n","        df_train, df_valid = make_fold('train-%d'%fold)\n","        train_dataset = SiimDataset(df_train, train_augment)\n","        valid_dataset = SiimDataset(df_valid, )\n","\n","        train_loader1 = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size,\n","            drop_last   = True,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            worker_init_fn=lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n","            collate_fn  = null_collate,\n","        )\n","        train_loader2 = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size,\n","            drop_last   = True,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            worker_init_fn=lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n","            collate_fn  = null_collate,\n","        )\n","        valid_loader  = DataLoader(\n","            valid_dataset,\n","            sampler = SequentialSampler(valid_dataset),\n","            batch_size  = batch_size,\n","            drop_last   = False,\n","            num_workers = 2,\n","            pin_memory  = True,\n","            collate_fn  = null_collate,\n","        )\n","\n","        log.write('train_dataset : \\n%s\\n'%(train_dataset))\n","        log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n","        log.write('\\n')\n","\n","\n","        ## net ----------------------------------------\n","        log.write('** net setting **\\n')\n","\n","        if is_mixed_precision:\n","            scaler = amp.GradScaler()\n","            net = AmpNet().cuda()\n","        else:\n","            net = Net().cuda()\n","\n","\n","        if initial_checkpoint is not None:\n","            f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n","            start_iteration = f['iteration']\n","            num_iteration = start_iteration + 10000\n","            start_epoch = f['epoch']\n","            state_dict  = f['state_dict']\n","            start_lr = f['lrate']\n","            best_map = f['map']\n","            net.load_state_dict(state_dict,strict=True)  #True\n","        else:\n","            start_iteration = 0\n","            start_epoch = 0\n","\n","\n","        log.write('net=%s\\n'%(type(net)))\n","        log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n","        log.write('\\n')\n","\n","        # -----------------------------------------------\n","        if 0: ##freeze\n","            for p in net.block0.backbone.parameters(): p.requires_grad = False\n","\n","\n","        #optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr), alpha=0.5, k=5)\n","        #optimizer = RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n","        optimizer = MADGRAD( filter(lambda p: p.requires_grad, net.parameters()), lr=start_lr, momentum= 0.9, weight_decay= 0, eps= 1e-06)\n","\n","\n","\n","        log.write('optimizer\\n  %s\\n'%(optimizer))\n","        log.write('\\n')\n","\n","\n","        ## start training here! ##############################################\n","        log.write('** start training here! **\\n')\n","        log.write('   fold = %d\\n'%(fold))\n","        log.write('   is_mixed_precision = %s \\n'%str(is_mixed_precision))\n","        log.write('   batch_size = %d\\n'%(batch_size))\n","        log.write('   experiment = %s\\n' % str(EXPERIMENT.split('/')[-2:]))\n","        log.write('                              |-----------VALID-------------------|-----TRAIN/BATCH -----|------TIME-----\\n')\n","        log.write('rate   plateau   iter   epoch | loss    map    rec    acc    auc  | loss0  loss1  loss2  |               \\n')\n","        log.write('---------------------------------------------------------------------------------------------------------\\n')\n","                  #0.00000     00   0.00*  0.00  | 0.000  0.000  0.000  0.000  0.000 | 0.000  0.000  0.000  |  0 hr 00 min\n","\n","        def message(mode='print'):\n","            if mode==('print'):\n","                asterisk = ' '\n","                loss = batch_loss\n","            if mode==('log'):\n","                asterisk = '*' if iteration in a_iter_save else ' '\n","                loss = train_loss\n","\n","            text = \\\n","                '%0.5f  %-7d %5.3f%s %4.2f  | '%(rate, rate_plateau, iteration/10000, asterisk, epoch,) +\\\n","                '%4.3f  %4.3f  %4.3f  %4.3f  %4.3f  | '%(*valid_loss,) +\\\n","                '%4.3f  %4.3f  %4.3f  | '%(*loss,) +\\\n","                '%s' % (time_to_str(timer() - start_timer,'min'))\n","\n","            return text\n","\n","        #----\n","        valid_loss = np.zeros(4,np.float32)\n","        train_loss = np.zeros(3,np.float32)\n","        batch_loss = np.zeros_like(train_loss)\n","        sum_train_loss = np.zeros_like(train_loss)\n","        sum_train = 0\n","        loss0 = torch.FloatTensor([0]).cuda().sum()\n","        loss1 = torch.FloatTensor([0]).cuda().sum()\n","        loss2 = torch.FloatTensor([0]).cuda().sum()\n","\n","\n","        start_timer = timer()\n","        iteration = start_iteration\n","        epoch = start_epoch\n","        rate = start_lr\n","        rate_plateau = 0\n","\n","        while  iteration < num_iteration:\n","            if (rate<min_lr): break\n","\n","            it_loader2 = iter(train_loader2)\n","            for t, batch1 in enumerate(train_loader1):\n","                \n","\n","                if (iteration % iter_valid == 0):\n","                        valid_loss = do_valid(net, valid_loader) \n","                        \n","                        if best_map < valid_loss[1]:\n","                          best_map = valid_loss[1]\n","                          a_iter_save.append(iteration)\n","                          rate_plateau=0\n","                          torch.save({\n","                            'state_dict': net.state_dict(),\n","                            'iteration': iteration,\n","                            'epoch': epoch,\n","                            'lrate': rate,\n","                            'map':best_map}, out_dir + '/checkpoint/best_model.pth')\n","                        else:\n","                          rate_plateau=rate_plateau+1\n","\n","                if (iteration % iter_log == 0):\n","                    print('\\r', end='', flush=True)\n","                    log.write(message(mode='log') + '\\n')\n","\n","                # learning rate schduler ------------\n","                rate = get_learning_rate(optimizer)\n","\n","                if (rate_plateau>MAX_LR_PLATEAU):\n","                  rate_plateau=0\n","                  rate = rate*LR_FACTOR\n","                  best_model_pth = out_dir+'/checkpoint/best_model.pth'\n","                  f = torch.load(best_model_pth, map_location=lambda storage, loc: storage)\n","                  state_dict  = f['state_dict']\n","                  iteration = f['iteration']\n","                  epoch = f['epoch']\n","\n","                  net.load_state_dict(state_dict,strict=True)\n","                  del optimizer\n","                  optimizer = MADGRAD( filter(lambda p: p.requires_grad, net.parameters()), lr=rate, momentum= 0.9, weight_decay= 0, eps= 1e-06)\n","                  break\n","\n","\n","                # mixup cutmix etc-----------\n","                with torch.no_grad():\n","                  prob = np.random.rand()\n","                  if prob<PROBS[0]:\n","                    batch2 = next(it_loader2)\n","                    mix_batch = do_mixup(batch1,batch2)\n","                  elif prob>=PROBS[0] and prob<PROBS[0]+PROBS[1]:\n","                    batch2 = next(it_loader2)\n","                    mix_batch = do_cutmix(batch1,batch2)\n","                  else:\n","                    mix_batch = {'image' :batch1['image'].cuda(),\n","                                 'mask'  :batch1['mask'].cuda(),\n","                                 'none':  batch1['none'].cuda()}\n","\n","\n","                # one iteration update  -------------\n","                batch_size = len(batch1['index'])\n","                image = mix_batch['image']\n","                truth_mask = mix_batch['mask']\n","                truth_mask = F.interpolate(truth_mask, size=MASK_SIZE, mode='bilinear', align_corners=False)\n","                label =  mix_batch['none']\n","\n","                #----\n","                net.train()\n","                optimizer.zero_grad()\n","\n","                if is_mixed_precision:\n","                    with amp.autocast():\n","                        logit, mask = data_parallel(net, image)\n","                        loss0 = F.binary_cross_entropy_with_logits(torch.reshape(logit,(-1,)), label)\n","                        loss1 = L1_FACTOR*F.binary_cross_entropy_with_logits(mask, truth_mask)\n","                        loss2 = loss0 + loss1\n","\n","                    #scaler.scale(loss0).backward()\n","                    #scaler.scale(loss1).backward()\n","                    scaler.scale(loss0+loss1).backward()\n","                    scaler.unscale_(optimizer)\n","                    #torch.nn.utils.clip_grad_norm_(net.parameters(), 2)\n","                    scaler.step(optimizer)\n","                    scaler.update()\n","\n","\n","                else :\n","                    assert(False)\n","                    print('fp32')\n","                    logit, mask = data_parallel(net, image)\n","                    loss0 = F.binary_cross_entropy(logit, label)\n","                    loss1 = F.binary_cross_entropy_with_logits(mask, truth_mask.shape)\n","\n","                    (loss0+loss1).backward()\n","                    optimizer.step()\n","\n","\n","                # print statistics  --------\n","                epoch += 1 / len(train_loader1)\n","                iteration += 1\n","\n","                batch_loss = np.array([loss0.item(), loss1.item(), loss2.item()])\n","                sum_train_loss += batch_loss\n","                sum_train += 1\n","                if iteration % 100 == 0:\n","                    train_loss = sum_train_loss / (sum_train + 1e-12)\n","                    sum_train_loss[...] = 0\n","                    sum_train = 0\n","\n","                print('\\r', end='', flush=True)\n","                print(message(mode='print'), end='', flush=True)\n","\n","\n","        log.write('\\n')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_7GTDVDz3Io","executionInfo":{"status":"ok","timestamp":1627084449986,"user_tz":-180,"elapsed":5237321,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}},"outputId":"cdeb29fc-6e0f-415a-8865-c3f41ee9f8ad"},"source":["run_train_mixup_cutmix()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","--- [START 2021-07-23_22-26-26] ----------------------------------------------------------------\n","\n","\t@common.py:  \n","\tpytorch\n","\t\tseed = 1627079194\n","\t\ttorch.__version__              = 1.9.0+cu102\n","\t\ttorch.version.cuda             = 10.2\n","\t\ttorch.backends.cudnn.version() = 7605\n","\t\tos['CUDA_VISIBLE_DEVICES']     = 0\n","\t\ttorch.cuda.device_count()      = 1\n","\t\ttorch.cuda.get_device_properties() = (name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n","\n","\n","\texpirement = SZ768_2CLASS_5FOLDS\n","\tout_dir  = /content/drive/My Drive/kaggle/covid19-det/output/SZ768_2CLASS_5FOLDS/fold2\n","\n","train_dataset : \n","\tlen = 4984\n","\tdf  = (4984, 11)\n","\tlabel distribution\n","\t\t 0     Negative for Pneumonia:  1371 (0.2751)\n","\t\t 1         Typical Appearance:  2362 (0.4739)\n","\t\t 2   Indeterminate Appearance:   868 (0.1742)\n","\t\t 3        Atypical Appearance:   383 (0.0768)\n","\n","valid_dataset : \n","\tlen = 1243\n","\tdf  = (1243, 11)\n","\tlabel distribution\n","\t\t 0     Negative for Pneumonia:   338 (0.2719)\n","\t\t 1         Typical Appearance:   596 (0.4795)\n","\t\t 2   Indeterminate Appearance:   214 (0.1722)\n","\t\t 3        Atypical Appearance:    95 (0.0764)\n","\n","\n","** net setting **\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ra-6c08e654.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ra-6c08e654.pth\n"],"name":"stderr"},{"output_type":"stream","text":["net=<class '__main__.AmpNet'>\n","\tinitial_checkpoint = /content/drive/My Drive/kaggle/covid19-det/output/SZ768_2CLASS_5FOLDS/fold2/checkpoint/best_model.pth\n","\n","optimizer\n","  MADGRAD (\n","Parameter Group 0\n","    eps: 1e-06\n","    lr: 0.0001\n","    momentum: 0.9\n","    weight_decay: 0\n",")\n","\n","** start training here! **\n","   fold = 2\n","   is_mixed_precision = True \n","   batch_size = 4\n","   experiment = ['SZ768_2CLASS_5FOLDS']\n","                              |-----------VALID-------------------|-----TRAIN/BATCH -----|------TIME-----\n","rate   plateau   iter   epoch | loss    map    rec    acc    auc  | loss0  loss1  loss2  |               \n","---------------------------------------------------------------------------------------------------------\n","0.00010  1       2.020  16.21  | 0.403  0.794  0.695  0.829  0.884  | 0.000  0.000  0.000  |  0 hr 00 min\n","0.00010  2       2.040  16.37  | 0.419  0.788  0.556  0.817  0.879  | 0.351  0.327  0.677  |  0 hr 02 min\n","0.00010  3       2.060  16.53  | 0.406  0.789  0.605  0.829  0.880  | 0.406  0.316  0.721  |  0 hr 03 min\n","0.00010  4       2.080  16.69  | 0.416  0.789  0.599  0.830  0.879  | 0.385  0.369  0.754  |  0 hr 05 min\n","0.00010  5       2.100  16.85  | 0.403  0.787  0.680  0.817  0.878  | 0.415  0.348  0.763  |  0 hr 07 min\n","0.00010  0       2.120* 17.01  | 0.414  0.798  0.649  0.833  0.887  | 0.335  0.325  0.660  |  0 hr 09 min\n","0.00010  0       2.140* 17.17  | 0.414  0.800  0.749  0.821  0.885  | 0.336  0.350  0.686  |  0 hr 10 min\n","0.00010  1       2.160  17.34  | 0.399  0.786  0.672  0.826  0.879  | 0.423  0.344  0.767  |  0 hr 12 min\n","0.00010  2       2.180  17.50  | 0.435  0.788  0.757  0.805  0.877  | 0.337  0.349  0.686  |  0 hr 14 min\n","0.00010  3       2.200  17.66  | 0.440  0.782  0.669  0.828  0.874  | 0.294  0.337  0.631  |  0 hr 16 min\n","0.00010  4       2.220  17.82  | 0.442  0.770  0.548  0.811  0.866  | 0.346  0.346  0.692  |  0 hr 17 min\n","0.00010  5       2.240  17.98  | 0.408  0.795  0.749  0.826  0.883  | 0.353  0.333  0.686  |  0 hr 19 min\n","0.00010  6       2.260  18.14  | 0.428  0.771  0.734  0.817  0.874  | 0.342  0.376  0.718  |  0 hr 21 min\n","0.00010  7       2.280  18.30  | 0.416  0.791  0.628  0.829  0.880  | 0.338  0.336  0.674  |  0 hr 23 min\n","0.00010  8       2.300  18.46  | 0.438  0.784  0.711  0.814  0.874  | 0.302  0.347  0.650  |  0 hr 25 min\n","0.00010  9       2.320  18.62  | 0.424  0.793  0.630  0.825  0.878  | 0.330  0.346  0.677  |  0 hr 26 min\n","0.00010  10      2.340  18.78  | 0.428  0.785  0.747  0.821  0.874  | 0.295  0.371  0.666  |  0 hr 28 min\n","0.00010  11      2.360  18.94  | 0.416  0.782  0.736  0.817  0.873  | 0.422  0.355  0.777  |  0 hr 30 min\n","0.00010  12      2.380  19.10  | 0.424  0.786  0.773  0.823  0.878  | 0.345  0.369  0.714  |  0 hr 32 min\n","0.00010  13      2.400  19.26  | 0.429  0.794  0.615  0.834  0.878  | 0.306  0.347  0.654  |  0 hr 33 min\n","0.00010  14      2.420  19.42  | 0.462  0.786  0.568  0.818  0.873  | 0.320  0.346  0.666  |  0 hr 35 min\n","0.00010  15      2.440  19.58  | 0.443  0.777  0.698  0.825  0.872  | 0.340  0.331  0.671  |  0 hr 37 min\n","0.00010  16      2.460  19.74  | 0.407  0.786  0.680  0.818  0.877  | 0.358  0.334  0.692  |  0 hr 39 min\n","0.00010  17      2.480  19.90  | 0.415  0.779  0.680  0.822  0.876  | 0.334  0.375  0.709  |  0 hr 40 min\n","0.00010  18      2.500  20.06  | 0.449  0.743  0.726  0.812  0.865  | 0.341  0.332  0.674  |  0 hr 42 min\n","0.00010  19      2.520  20.22  | 0.405  0.791  0.726  0.834  0.885  | 0.329  0.341  0.670  |  0 hr 44 min\n","0.00010  20      2.540  20.39  | 0.434  0.778  0.752  0.815  0.877  | 0.315  0.354  0.668  |  0 hr 46 min\n","0.00010  21      2.560  20.55  | 0.430  0.781  0.693  0.826  0.877  | 0.320  0.337  0.657  |  0 hr 47 min\n","0.00001  1       2.140* 17.17  | 0.414  0.800  0.749  0.821  0.885  | 0.320  0.337  0.657  |  0 hr 48 min\n","0.00001  0       2.160* 17.34  | 0.407  0.803  0.760  0.827  0.886  | 0.342  0.334  0.676  |  0 hr 50 min\n","0.00001  1       2.180  17.50  | 0.404  0.799  0.705  0.830  0.885  | 0.316  0.353  0.669  |  0 hr 51 min\n","0.00001  2       2.200  17.66  | 0.406  0.796  0.659  0.827  0.882  | 0.347  0.335  0.683  |  0 hr 53 min\n","0.00001  3       2.220  17.82  | 0.406  0.798  0.716  0.831  0.884  | 0.327  0.350  0.677  |  0 hr 55 min\n","0.00001  4       2.240  17.98  | 0.412  0.797  0.718  0.825  0.882  | 0.331  0.319  0.650  |  0 hr 57 min\n","0.00001  5       2.260  18.14  | 0.406  0.799  0.685  0.833  0.883  | 0.310  0.334  0.644  |  0 hr 58 min\n","0.00001  6       2.280  18.30  | 0.409  0.796  0.685  0.828  0.882  | 0.332  0.350  0.682  |  1 hr 00 min\n","0.00001  7       2.300  18.46  | 0.413  0.796  0.713  0.832  0.883  | 0.331  0.326  0.657  |  1 hr 02 min\n","0.00001  8       2.320  18.62  | 0.410  0.797  0.677  0.828  0.882  | 0.353  0.345  0.698  |  1 hr 04 min\n","0.00001  9       2.340  18.78  | 0.406  0.797  0.664  0.836  0.883  | 0.316  0.349  0.665  |  1 hr 05 min\n","0.00001  10      2.360  18.94  | 0.408  0.795  0.695  0.832  0.881  | 0.332  0.355  0.687  |  1 hr 07 min\n","0.00001  11      2.380  19.10  | 0.410  0.800  0.654  0.833  0.884  | 0.300  0.351  0.651  |  1 hr 09 min\n","0.00001  12      2.400  19.26  | 0.409  0.794  0.708  0.829  0.881  | 0.368  0.310  0.677  |  1 hr 11 min\n","0.00001  13      2.420  19.42  | 0.426  0.789  0.646  0.825  0.877  | 0.321  0.319  0.640  |  1 hr 12 min\n","0.00001  14      2.440  19.58  | 0.410  0.802  0.677  0.841  0.884  | 0.358  0.312  0.670  |  1 hr 14 min\n","0.00001  15      2.460  19.74  | 0.401  0.800  0.677  0.841  0.884  | 0.362  0.338  0.700  |  1 hr 16 min\n","0.00001  16      2.480  19.90  | 0.409  0.799  0.705  0.832  0.882  | 0.325  0.337  0.662  |  1 hr 18 min\n","0.00001  17      2.500  20.06  | 0.409  0.801  0.705  0.833  0.883  | 0.300  0.348  0.648  |  1 hr 19 min\n","0.00001  18      2.520  20.22  | 0.407  0.800  0.636  0.835  0.883  | 0.360  0.351  0.711  |  1 hr 21 min\n","0.00001  19      2.540  20.39  | 0.414  0.798  0.742  0.822  0.882  | 0.362  0.336  0.698  |  1 hr 23 min\n","0.00001  20      2.560  20.55  | 0.417  0.797  0.734  0.817  0.882  | 0.351  0.288  0.639  |  1 hr 25 min\n","0.00001  21      2.580  20.71  | 0.416  0.797  0.649  0.830  0.881  | 0.292  0.322  0.614  |  1 hr 26 min\n","\n"],"name":"stdout"}]}]}