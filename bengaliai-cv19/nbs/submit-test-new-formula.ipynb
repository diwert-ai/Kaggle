{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"submit-test-new-formula.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"mAfeZ5qBigs3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"4ace34dd-262c-48b8-8eec-c2c879915294","executionInfo":{"status":"ok","timestamp":1577822363874,"user_tz":-180,"elapsed":25831,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"2TDwYhPchzgj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4283efc0-ba1e-4ddb-d1ab-9279ea783282","executionInfo":{"status":"ok","timestamp":1577822368164,"user_tz":-180,"elapsed":960,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/content/drive/My Drive/kaggle/bengali'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/kaggle/bengali/nbs/submit-test-new-formula.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xD_WxoX0iNpf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b99ca015-0cee-46a9-a387-014958bed040","executionInfo":{"status":"ok","timestamp":1577822251392,"user_tz":-180,"elapsed":635,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["%tensorflow_version 2.x"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"JI175qschzgo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"b418dd7a-d74c-4482-c391-7d7f1f6042f1","executionInfo":{"status":"ok","timestamp":1577822373980,"user_tz":-180,"elapsed":1968,"user":{"displayName":"Drew Wert","photoUrl":"","userId":"15737305534098303053"}}},"source":["import tensorflow as tf\n","import keras\n","from keras.layers import LeakyReLU\n","from keras.layers.normalization import BatchNormalization\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tqdm.auto import tqdm\n","import cv2"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"ahsMGRz0hzgs","colab_type":"code","colab":{}},"source":["def build_model(model_seq, need_compile=False):  \n","    x_in = tf.keras.layers.Input(shape=(64, 64, 1))\n","    x = model_seq(x_in)\n","    out_grapheme = tf.keras.layers.Dense(168, activation='softmax', name='grapheme')(x)\n","    out_vowel = tf.keras.layers.Dense(11, activation='softmax', name='vowel')(x)\n","    out_consonant = tf.keras.layers.Dense(7, activation='softmax', name='consonant')(x)\n","    \n","    model = tf.keras.Model(inputs=x_in, outputs=[out_grapheme, out_vowel, out_consonant])\n","    \n","    if need_compile==True:model.compile(optimizer=RMSprop(lr=initial_learningrate), loss='categorical_crossentropy', metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qJvGGsvehzgv","colab_type":"code","colab":{}},"source":["model_seq = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', input_shape=(64, 64, 1)),\n","    tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","    tf.keras.layers.Conv2D(filters=64,  kernel_size=(3,3), padding='same'),\n","    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(0.2),\n","    \n","    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same'),\n","    tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same'),\n","    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","    \n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),    \n","    \n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same'),\n","    tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same'),\n","    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),\n","    \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(256),\n","    tf.keras.layers.LeakyReLU(alpha=0.1),\n","    tf.keras.layers.BatchNormalization(),    \n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"OeWSsnvdhzgz","colab_type":"code","colab":{}},"source":["model = build_model(model_seq)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"E_AT6Tcchzg2","colab_type":"code","colab":{}},"source":["model.load_weights('/kaggle/input/eps80-wloss/eps80_wloss.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"aT8dpCD7hzg5","colab_type":"code","colab":{}},"source":["SIZE=128\n","HEIGHT = 137\n","WIDTH = 236\n","\n","def bbox(img):\n","    rows = np.any(img, axis=1)\n","    cols = np.any(img, axis=0)\n","    rmin, rmax = np.where(rows)[0][[0, -1]]\n","    cmin, cmax = np.where(cols)[0][[0, -1]]\n","    return rmin, rmax, cmin, cmax\n","\n","def crop_resize(img0, size=SIZE, pad=16):\n","    #crop a box around pixels large than the threshold \n","    #some images contain line at the sides\n","    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n","    #cropping may cut too much, so we need to add it back\n","    xmin = xmin - 13 if (xmin > 13) else 0\n","    ymin = ymin - 10 if (ymin > 10) else 0\n","    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n","    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n","    img = img0[ymin:ymax,xmin:xmax]\n","    #remove lo intensity pixels as noise\n","    img[img < 28] = 0\n","    lx, ly = xmax-xmin,ymax-ymin\n","    l = max(lx,ly) + pad\n","    #make sure that the aspect ratio is kept in rescaling\n","    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n","    return cv2.resize(img,(size,size))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"NGAPWUAkhzg7","colab_type":"code","colab":{}},"source":["def test_batch_generator(frame, batch_size=64):    \n","    \n","    num_imgs = len(frame)\n","    stats = (0.0692, 0.2051)\n","    \n","    for batch_start in range(0, num_imgs,batch_size):   \n","        \n","            cur_batch_size = min(num_imgs,batch_start+batch_size)-batch_start\n","            \n","            idx = np.arange(batch_start,batch_start+cur_batch_size)\n","            names_batch = frame.iloc[idx,0].values\n","            imgs_batch = 255 - frame.iloc[idx, 1:].values.reshape(-1, HEIGHT, WIDTH,1).astype(np.uint8)\n","            \n","            resized_imgs_batch = np.zeros((cur_batch_size,64,64,1))\n","            \n","            for j in range(cur_batch_size):\n","                img = (imgs_batch[j,:,:,0]*(255.0/imgs_batch[j,:,:,0].max())).astype(np.uint8)\n","                img = crop_resize(img)\n","                img = (img.astype(np.float32)/255.0 - stats[0])/stats[1]\n","                img = cv2.resize(img,(64,64)).reshape(64,64,1)\n","                resized_imgs_batch[j,] = img\n","                \n","            yield resized_imgs_batch,names_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"WTV21g9Hhzg-","colab_type":"code","colab":{}},"source":["P_TEST_MODE=True\n","\n","TEST_F = ['/kaggle/input/bengaliaicv19feather/test_image_data_0.feather',\n","          '/kaggle/input/bengaliaicv19feather/test_image_data_1.feather',\n","          '/kaggle/input/bengaliaicv19feather/test_image_data_2.feather',\n","          '/kaggle/input/bengaliaicv19feather/test_image_data_3.feather']\n","\n","TEST_P = ['/kaggle/input/bengaliai-cv19/test_image_data_0.parquet',\n","          '/kaggle/input/bengaliai-cv19/test_image_data_1.parquet',\n","          '/kaggle/input/bengaliai-cv19/test_image_data_2.parquet',\n","          '/kaggle/input/bengaliai-cv19/test_image_data_3.parquet']\n","\n","if P_TEST_MODE==True: TEST = TEST_P\n","else                : TEST = TEST_F\n","\n","batch_size=1024\n","row_id,target = [],[]\n","\n","for fname in TEST:\n","    if P_TEST_MODE == True: frame = pd.read_parquet(fname) \n","    else:                   frame = pd.read_feather(fname)\n","        \n","    test_gen = test_batch_generator(frame,batch_size=batch_size)\n","    \n","    for batch_x,batch_name in tqdm(test_gen):\n","            batch_predict = model.predict(batch_x)\n","            for idx,name in enumerate(batch_name):\n","                row_id += [f'{name}_consonant_diacritic',f'{name}_grapheme_root',f'{name}_vowel_diacritic']\n","                target += [ np.argmax(batch_predict[2],axis=1)[idx],\n","                            np.argmax(batch_predict[0],axis=1)[idx],\n","                            np.argmax(batch_predict[1],axis=1)[idx]]\n","                \n","    frame.drop(frame.index.values,inplace=True)\n","    \n","sub_df = pd.DataFrame({'row_id': row_id, 'target': target})\n","sub_df.to_csv('submission.csv', index=False)\n","sub_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"PkcO79cchzhB","colab_type":"code","colab":{}},"source":["sub_df"],"execution_count":0,"outputs":[]}]}